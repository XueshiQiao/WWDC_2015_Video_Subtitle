
00:00:25.461 --> 00:00:27.461 A:middle
[Applause]

00:00:27.906 --> 00:00:28.206 A:middle
&gt;&gt; CHAD WOOLF: Thank you.

00:00:31.486 --> 00:00:32.555 A:middle
Thank you.

00:00:32.555 --> 00:00:33.316 A:middle
I'm Chad Woolf.

00:00:33.626 --> 00:00:34.536 A:middle
&gt;&gt; KRIS MARKEL: I'm Kris Markel.

00:00:34.536 --> 00:00:35.026 A:middle
&gt;&gt; CHAD WOOLF:

00:00:35.026 --> 00:00:37.256 A:middle
We are performance tools
engineers for Apple.

00:00:37.696 --> 00:00:39.876 A:middle
This is session 412.

00:00:39.876 --> 00:00:43.626 A:middle
We'll talking about
profiling in depth.

00:00:43.626 --> 00:00:46.476 A:middle
This will talk about the time
profiler in Instruments and how

00:00:46.476 --> 00:00:49.146 A:middle
to use it to optimize
your applications.

00:00:50.336 --> 00:00:52.946 A:middle
Time profiler is place to go
when you're trying to figure

00:00:52.946 --> 00:00:56.106 A:middle
out where your application is
spending the bulk of its time.

00:00:56.336 --> 00:00:56.826 A:middle
An example.

00:00:57.406 --> 00:01:00.076 A:middle
It is useful when trying



00:00:57.406 --> 00:01:00.076 A:middle
It is useful when trying

00:01:00.076 --> 00:01:02.736 A:middle
to discover what the
application is doing at runtime.

00:01:02.736 --> 00:01:04.465 A:middle
You want to see who
is calling what.

00:01:05.996 --> 00:01:08.226 A:middle
Our session breaks
down a bit like this.

00:01:08.226 --> 00:01:11.166 A:middle
We'll talk a bit about the
motivation on why we wanted

00:01:11.166 --> 00:01:14.156 A:middle
to create a session devoted
to the time profiler only.

00:01:15.036 --> 00:01:18.366 A:middle
But the session will
revolve around demonstrations

00:01:18.366 --> 00:01:21.226 A:middle
and showing you details
on how it works

00:01:21.366 --> 00:01:25.986 A:middle
and how your applications
work below the source level.

00:01:27.496 --> 00:01:29.466 A:middle
Then we'll give you
final tips on how

00:01:29.466 --> 00:01:31.246 A:middle
to use the time profiler
on your own.

00:01:31.246 --> 00:01:34.196 A:middle
Quickly about our motivation,
it comes from the creation

00:01:34.196 --> 00:01:35.796 A:middle
of Instruments 7 itself.

00:01:36.806 --> 00:01:38.786 A:middle
With Instrument 7 we wanted
to go with a new look and feel

00:01:38.786 --> 00:01:40.946 A:middle
which meant new artwork
but it also meant

00:01:40.946 --> 00:01:44.366 A:middle
that for the new feel, we
wanted it to be more responsive

00:01:45.036 --> 00:01:46.566 A:middle
and we wanted to feel smoother.

00:01:46.726 --> 00:01:48.656 A:middle
We'll do performance
optimizations

00:01:48.786 --> 00:01:50.136 A:middle
for our UI in general.

00:01:51.436 --> 00:01:53.256 A:middle
We also wanted to try
new graphing styles.

00:01:53.256 --> 00:01:55.906 A:middle
These graphing styles were
things that we wanted to do

00:01:55.906 --> 00:01:57.656 A:middle
in the past but didn't
have the performance

00:01:57.656 --> 00:01:59.956 A:middle
to in our existing graphic code.



00:02:00.306 --> 00:02:04.246 A:middle
We knew that we would have
to focus on the rendering

00:02:04.766 --> 00:02:08.076 A:middle
which is a pretty difficult
piece of application.

00:02:08.076 --> 00:02:10.996 A:middle
Instruments have to deal
with hundreds of thousands,

00:02:10.996 --> 00:02:13.646 A:middle
sometimes millions of data
points and has to try to crunch

00:02:13.646 --> 00:02:17.496 A:middle
that down into a
presentation that's both simple

00:02:17.496 --> 00:02:18.506 A:middle
and easy to understand.

00:02:18.806 --> 00:02:22.786 A:middle
There is definitely algorithm
complexities in there.

00:02:22.786 --> 00:02:25.796 A:middle
What that meant for us, we had
to rewrite a significant portion

00:02:25.796 --> 00:02:29.296 A:middle
of our application which is
the track view which lives

00:02:29.296 --> 00:02:31.486 A:middle
up at the top of the app.

00:02:31.486 --> 00:02:35.336 A:middle
Chris and I over winter took our
design for the new track view

00:02:35.946 --> 00:02:38.476 A:middle
and we started building it up
out of a series of prototypes.

00:02:38.616 --> 00:02:41.236 A:middle
We didn't do the prototyping
in Instruments itself,

00:02:41.236 --> 00:02:43.476 A:middle
we broke it out in a separate
application to keep it simple.

00:02:44.196 --> 00:02:47.926 A:middle
This is what one of the
last prototypes looked like.

00:02:49.416 --> 00:02:51.866 A:middle
Now while we were
prototyping, a thing we did,

00:02:51.866 --> 00:02:53.196 A:middle
we set a performance budget.

00:02:53.876 --> 00:02:55.316 A:middle
As we layered on feature

00:02:55.316 --> 00:02:58.886 A:middle
after feature we were constantly
evaluating our performance

00:02:58.886 --> 00:03:00.946 A:middle
of our code against the budget.



00:02:58.886 --> 00:03:00.946 A:middle
of our code against the budget.

00:03:01.816 --> 00:03:04.816 A:middle
When we found we were exceeding
the budget we would use the time

00:03:04.816 --> 00:03:06.406 A:middle
profiler to figure out where

00:03:06.406 --> 00:03:08.246 A:middle
in our application
things were going wrong.

00:03:08.246 --> 00:03:12.996 A:middle
Sometimes it was an easy
fix but sometimes it wasn't.

00:03:13.726 --> 00:03:14.926 A:middle
Since we were prototyping,

00:03:15.256 --> 00:03:17.246 A:middle
even some of the bigger
structural changes we had

00:03:17.246 --> 00:03:18.476 A:middle
to make to get the
performance back

00:03:18.476 --> 00:03:20.106 A:middle
on track was still fairly easy.

00:03:21.596 --> 00:03:22.856 A:middle
When we integrated it back

00:03:22.856 --> 00:03:26.116 A:middle
into Instruments we use
the time profiler again

00:03:26.206 --> 00:03:28.866 A:middle
to find the hot spots in
our integration points,

00:03:28.996 --> 00:03:32.636 A:middle
and after a few iterations, we
had a version of Instruments 7

00:03:32.636 --> 00:03:34.286 A:middle
which was meeting our
performance goals.

00:03:35.306 --> 00:03:38.086 A:middle
We were thrilled with how
the time profiler got us

00:03:38.116 --> 00:03:40.966 A:middle
through this winter,
that when WWDC 2015 came,

00:03:40.996 --> 00:03:45.336 A:middle
we wanted to create a session
that talks about time profiler

00:03:45.646 --> 00:03:47.516 A:middle
and the problems that it's
really good at solving.

00:03:48.636 --> 00:03:51.796 A:middle
We wanted to share
our experience

00:03:51.796 --> 00:03:52.906 A:middle
when writing the track view.

00:03:53.986 --> 00:03:55.246 A:middle
What we did this year,

00:03:55.246 --> 00:03:58.506 A:middle
we created a demonstration
application on iOS

00:03:59.176 --> 00:04:02.626 A:middle
that looks similar to the
first track view prototypes



00:03:59.176 --> 00:04:02.626 A:middle
that looks similar to the
first track view prototypes

00:04:03.546 --> 00:04:06.636 A:middle
and we set performance
targets for ourselves,

00:04:06.636 --> 00:04:10.416 A:middle
100,000 data points is
what we wanted to graph,

00:04:11.086 --> 00:04:15.236 A:middle
we wanted a perfect 60 frame per
second for panning and zooming.

00:04:16.005 --> 00:04:18.826 A:middle
We wanted to make it work on
a iPad mini 1st generation.

00:04:19.495 --> 00:04:21.435 A:middle
We picked the iPad
mini 1st gen --

00:04:21.435 --> 00:04:24.376 A:middle
you know what I'm
talking about --

00:04:24.376 --> 00:04:27.056 A:middle
we knew it would
work well on all

00:04:27.056 --> 00:04:30.776 A:middle
of the other platforms
especially the later platforms.

00:04:30.776 --> 00:04:32.436 A:middle
Chris will show you
the application,

00:04:32.696 --> 00:04:36.766 A:middle
he'll time profile it, and he's
going to show you the things

00:04:36.846 --> 00:04:39.456 A:middle
that we found when putting
this together for you.

00:04:41.066 --> 00:04:41.596 A:middle
&gt;&gt; KRIS MARKEL: Thank you, Chad.

00:04:41.836 --> 00:04:45.276 A:middle
Here I have the prototype
application of an Xcode,

00:04:45.596 --> 00:04:48.076 A:middle
and I want to call
out a few things.

00:04:48.076 --> 00:04:51.246 A:middle
Our initial implementation we
discovered can't handle even

00:04:51.246 --> 00:04:52.806 A:middle
close to 100,000 data points.

00:04:53.156 --> 00:04:55.946 A:middle
Initially we're working with
10,000 data points to get going.

00:04:56.386 --> 00:04:59.766 A:middle
Another important point, you
should do your time profiling

00:04:59.766 --> 00:05:02.616 A:middle
on release builds, you
want to take advantage



00:04:59.766 --> 00:05:02.616 A:middle
on release builds, you
want to take advantage

00:05:02.616 --> 00:05:05.906 A:middle
of the compiler optimizations
while you're profiling.

00:05:05.906 --> 00:05:09.976 A:middle
I'll go ahead, start profiling
the application and to do

00:05:09.976 --> 00:05:12.806 A:middle
that I'll, from the product
menu, choose profile.

00:05:13.596 --> 00:05:17.416 A:middle
This will build the application,
install it on the iPad and bring

00:05:17.416 --> 00:05:18.966 A:middle
up the Instrument template user.

00:05:19.576 --> 00:05:22.926 A:middle
Here it is, time profiler
is selected for me.

00:05:22.926 --> 00:05:24.066 A:middle
I'll click choose.

00:05:24.486 --> 00:05:27.216 A:middle
Here you will see Instruments
in our new track view

00:05:27.466 --> 00:05:29.296 A:middle
and we'll get back
to that in a minute.

00:05:29.366 --> 00:05:31.276 A:middle
Right now I'll go ahead
and start recording,

00:05:31.736 --> 00:05:34.796 A:middle
click the record button,
we'll show you the app.

00:05:35.536 --> 00:05:39.266 A:middle
I want to emphasize what you see
here, this is not the simulator,

00:05:39.266 --> 00:05:43.016 A:middle
this is QuickTime mirroring that
which is already on the app.

00:05:43.806 --> 00:05:48.516 A:middle
Here's our graph, I'll go ahead
and scroll, scrolling isn't bad,

00:05:48.516 --> 00:05:52.476 A:middle
it is not bad, I'll zoom out
by pinching, it is okay at fist

00:05:52.476 --> 00:05:55.436 A:middle
and then starts to
stutter, stutter,

00:05:55.806 --> 00:05:57.826 A:middle
stutter, that's pretty bad.

00:05:58.776 --> 00:06:02.256 A:middle
Now, finally, I'm going to
just scroll back and forth



00:05:58.776 --> 00:06:02.256 A:middle
Now, finally, I'm going to
just scroll back and forth

00:06:02.256 --> 00:06:04.106 A:middle
with my finger, I'm
actually moving my finger

00:06:04.106 --> 00:06:07.666 A:middle
but the display is not updating,
it is very, very laggy.

00:06:08.206 --> 00:06:10.516 A:middle
That's very poor performance.

00:06:11.226 --> 00:06:12.866 A:middle
Let's look at what's going on.

00:06:13.126 --> 00:06:14.986 A:middle
Let's go back to
Xcode -- Instruments.

00:06:14.986 --> 00:06:16.746 A:middle
We'll stop the profiler

00:06:16.906 --> 00:06:19.316 A:middle
and quickly show you
the new track view.

00:06:19.726 --> 00:06:21.666 A:middle
Here we have the CPU usage.

00:06:22.066 --> 00:06:24.396 A:middle
What this is, this is
the average CPU usage

00:06:24.576 --> 00:06:26.306 A:middle
for specific unit of time.

00:06:26.616 --> 00:06:28.706 A:middle
That time depends on
your current zoom level.

00:06:29.106 --> 00:06:31.466 A:middle
You see the different
parts as I use my app

00:06:31.916 --> 00:06:33.406 A:middle
where it was spending time.

00:06:33.406 --> 00:06:36.766 A:middle
This is scrolling, the zooming
out, this is the scrolling back

00:06:36.766 --> 00:06:38.786 A:middle
and forth while zoomed out.

00:06:38.786 --> 00:06:41.486 A:middle
A nice thing about the new track
view is that I can go ahead

00:06:41.486 --> 00:06:46.406 A:middle
and use this pinch gesture
to zoom in on a piece of data

00:06:46.406 --> 00:06:47.206 A:middle
that I'm interested in.

00:06:47.786 --> 00:06:50.866 A:middle
If you're not using a Trackpad,
you can hold down the option key

00:06:50.986 --> 00:06:54.476 A:middle
and scroll up and down
to zoom in and out.

00:06:54.836 --> 00:06:57.706 A:middle
I want to focus on this
particular piece of data,

00:06:57.896 --> 00:06:59.706 A:middle
the activity right here.



00:07:00.026 --> 00:07:01.716 A:middle
I was scrolling here.

00:07:01.716 --> 00:07:05.596 A:middle
To do that, I'll apply a filter,
that's just a click and drag

00:07:06.276 --> 00:07:11.476 A:middle
and it selecting just those
specific samples so I can focus

00:07:11.476 --> 00:07:12.566 A:middle
on that particular data.

00:07:13.576 --> 00:07:16.386 A:middle
I'll create more
space down here.

00:07:17.056 --> 00:07:19.356 A:middle
Down here this is
our detailed view.

00:07:19.946 --> 00:07:22.756 A:middle
What this is showing
us is how many --

00:07:22.756 --> 00:07:25.976 A:middle
the percentage of time
profiler samples we have inside

00:07:25.976 --> 00:07:27.496 A:middle
of a particular function
or method

00:07:27.746 --> 00:07:28.846 A:middle
and then we have
the symbol name.

00:07:28.846 --> 00:07:31.846 A:middle
Here is our percentage
and here is our symbols.

00:07:32.396 --> 00:07:33.926 A:middle
Now the first thing
you usually do

00:07:33.926 --> 00:07:37.126 A:middle
when you time profile is you
start to expand these out

00:07:37.606 --> 00:07:42.586 A:middle
and looking for kind of a --
comparing the numbers over here

00:07:42.586 --> 00:07:45.096 A:middle
with specific methods
over here, function.

00:07:45.416 --> 00:07:48.046 A:middle
Looking for things that kind
of stand out as, you know,

00:07:48.416 --> 00:07:50.396 A:middle
jump out at you as something
that's worthy of investigating.

00:07:50.876 --> 00:07:54.476 A:middle
Another option, if we go over
to the inspector pane and click

00:07:54.476 --> 00:07:58.666 A:middle
on the extended detail, we
see the heaviest stack trace.

00:07:59.156 --> 00:08:00.246 A:middle
This is for the main thread.



00:07:59.156 --> 00:08:00.246 A:middle
This is for the main thread.

00:08:00.666 --> 00:08:04.086 A:middle
This is where focusing here is
where I'll get the most bang

00:08:04.086 --> 00:08:07.126 A:middle
for my buck when doing
a time profiling trying

00:08:07.126 --> 00:08:08.266 A:middle
to make performance
improvements.

00:08:08.266 --> 00:08:10.276 A:middle
Let's see what's going on.

00:08:10.456 --> 00:08:14.486 A:middle
The main is calling
application main, run loop,

00:08:14.486 --> 00:08:18.326 A:middle
there is core animation
work happening, some --

00:08:18.326 --> 00:08:22.956 A:middle
there is nothing
standing out as something

00:08:22.956 --> 00:08:27.566 A:middle
that seems out of the ordinary.

00:08:28.086 --> 00:08:31.246 A:middle
In fact, this is a really common
occurrence when profiling.

00:08:31.356 --> 00:08:33.765 A:middle
You look at what the
application is doing the most,

00:08:34.216 --> 00:08:36.916 A:middle
well it doesn't look like it
is doing anything special.

00:08:36.916 --> 00:08:38.405 A:middle
There is nothing -- no call

00:08:38.405 --> 00:08:40.785 A:middle
to compute the 40th
Fibonacci number here

00:08:40.785 --> 00:08:41.466 A:middle
in here or something.

00:08:42.446 --> 00:08:45.496 A:middle
However, you know,
looking at this call stack,

00:08:45.496 --> 00:08:48.016 A:middle
this stack trace, there is
something I know what my

00:08:48.016 --> 00:08:48.996 A:middle
application does.

00:08:48.996 --> 00:08:52.056 A:middle
It is a simple prototype
app, what it does,

00:08:52.056 --> 00:08:55.706 A:middle
it builds a path
and it draws a path.

00:08:55.706 --> 00:08:56.866 A:middle
I can actually see in here

00:08:56.866 --> 00:08:58.966 A:middle
that there is a call,
a CG context path.

00:08:59.246 --> 00:09:02.396 A:middle
It is not called by my code
according to the stack trace.



00:08:59.246 --> 00:09:02.396 A:middle
It is not called by my code
according to the stack trace.

00:09:02.736 --> 00:09:05.096 A:middle
It is here, it is taking
up a fair amount of time.

00:09:05.096 --> 00:09:07.056 A:middle
I'll go ahead, click on
that, take a look at that.

00:09:07.866 --> 00:09:11.716 A:middle
If we look back at our call
tree I do see something

00:09:11.716 --> 00:09:12.286 A:middle
interesting here.

00:09:12.286 --> 00:09:14.966 A:middle
What we have, we have
the draw path according

00:09:14.966 --> 00:09:16.386 A:middle
to this call tree is called

00:09:16.386 --> 00:09:19.076 A:middle
by this draw layer
method on UI view.

00:09:19.426 --> 00:09:24.266 A:middle
That's also calling our
drawRect for the graph view.

00:09:24.756 --> 00:09:26.796 A:middle
That's taking a fair
amount of time.

00:09:26.796 --> 00:09:30.326 A:middle
That's one of the
things that the app does.

00:09:30.326 --> 00:09:34.376 A:middle
If I look at the time over here,
context draw path is taking up,

00:09:34.536 --> 00:09:38.816 A:middle
you know, 55% of the samples but
the drawRect, it in very few.

00:09:38.816 --> 00:09:42.556 A:middle
This is interesting,
if I double-click

00:09:42.626 --> 00:09:45.046 A:middle
on the drawRect method it will
take me to the source code.

00:09:45.696 --> 00:09:47.816 A:middle
I see, if you look
to the bottom,

00:09:47.866 --> 00:09:51.806 A:middle
I actually do call draw path
from the drawRect method

00:09:52.046 --> 00:09:55.126 A:middle
but it is not showing
up in any sample.

00:09:55.426 --> 00:09:58.426 A:middle
Everything in here
is an add path.

00:09:58.696 --> 00:10:01.356 A:middle
This is unusual especially



00:09:58.696 --> 00:10:01.356 A:middle
This is unusual especially

00:10:01.356 --> 00:10:05.106 A:middle
since my expectation is my own
drawRect method would take a

00:10:05.106 --> 00:10:05.796 A:middle
while to run.

00:10:05.796 --> 00:10:08.286 A:middle
It is basically half
of what my app does.

00:10:08.696 --> 00:10:10.046 A:middle
Looking at this,
I actually notice

00:10:10.046 --> 00:10:12.566 A:middle
that while drawRect
returns a void

00:10:12.836 --> 00:10:16.346 A:middle
and context draw path is
the last method called

00:10:16.956 --> 00:10:18.856 A:middle
and this is probably a case

00:10:18.856 --> 00:10:20.526 A:middle
of what's called Tail
Call Elimination.

00:10:20.946 --> 00:10:25.276 A:middle
To tell us more about Tail
Call Elimination and how

00:10:25.276 --> 00:10:29.766 A:middle
to verify that, back to Chad.

00:10:30.456 --> 00:10:30.716 A:middle
&gt;&gt; CHAD WOOLF: Okay.

00:10:30.816 --> 00:10:34.216 A:middle
So to explain the situation
that Kris is seeing we have

00:10:34.216 --> 00:10:38.116 A:middle
to understand how the time
profiler sees what's calling

00:10:38.116 --> 00:10:39.396 A:middle
what inside of your application.

00:10:40.046 --> 00:10:41.506 A:middle
This is going to get technical,

00:10:41.546 --> 00:10:44.216 A:middle
I'll walk through
it step by step.

00:10:44.426 --> 00:10:48.196 A:middle
On the left, we have the code
for drawRect and on the right,

00:10:48.196 --> 00:10:51.266 A:middle
we have what you would imagine
the stack to look like for

00:10:51.266 --> 00:10:54.676 A:middle
that thread, right before the
UIKit calls into the drawRect.

00:10:55.146 --> 00:10:57.206 A:middle
When that call is made

00:10:57.206 --> 00:11:01.036 A:middle
to the drawRect it will do what
most functions and methods do,



00:10:57.206 --> 00:11:01.036 A:middle
to the drawRect it will do what
most functions and methods do,

00:11:01.126 --> 00:11:02.856 A:middle
to establish their
own call frame.

00:11:03.866 --> 00:11:07.776 A:middle
That starts off by first
pushing the return address

00:11:07.776 --> 00:11:10.186 A:middle
from the link register
and the previous value

00:11:10.186 --> 00:11:11.716 A:middle
of the frame Pointer
on the stack.

00:11:12.036 --> 00:11:15.276 A:middle
Now drawRect knows how
to return to its caller

00:11:15.276 --> 00:11:16.366 A:middle
and restore the frame Pointer.

00:11:18.086 --> 00:11:19.236 A:middle
Now the next thing that happens,

00:11:19.286 --> 00:11:21.566 A:middle
we take the frame Pointer
set up to the new base.

00:11:23.016 --> 00:11:26.316 A:middle
Then drawRect will make
room for its local variables

00:11:26.316 --> 00:11:28.566 A:middle
and the compiler scratch
space and that's --

00:11:28.566 --> 00:11:30.196 A:middle
now we have a frame
for drawRect.

00:11:30.746 --> 00:11:34.506 A:middle
Now the code starts to run
and we come down to draw path

00:11:35.806 --> 00:11:37.506 A:middle
and draw path does
the same thing.

00:11:37.536 --> 00:11:39.176 A:middle
It pushes the own
frame on to the stack.

00:11:40.396 --> 00:11:43.436 A:middle
The way time profiler works,
it uses a service in the kernel

00:11:43.726 --> 00:11:45.726 A:middle
that will sample what
the CPUs are doing

00:11:45.806 --> 00:11:47.196 A:middle
at about 1000x per second.

00:11:48.396 --> 00:11:50.506 A:middle
In this case, if
we take a sample,

00:11:50.906 --> 00:11:54.006 A:middle
we see that we're running
inside of context draw path.

00:11:54.366 --> 00:11:58.316 A:middle
Then the kernal looks at the
frame Pointer register to see

00:11:58.316 --> 00:12:01.496 A:middle
where the base of that
function's frame is



00:11:58.316 --> 00:12:01.496 A:middle
where the base of that
function's frame is

00:12:01.806 --> 00:12:03.666 A:middle
and find the return
address of who called it.

00:12:04.306 --> 00:12:08.176 A:middle
Now we can see that drawRect
called into draw path.

00:12:09.256 --> 00:12:10.446 A:middle
If we want to see who called

00:12:10.446 --> 00:12:13.776 A:middle
into drawRect we can use the
frame Pointers that were pushed

00:12:13.776 --> 00:12:16.596 A:middle
on the stack to find
the base of drawRect

00:12:17.226 --> 00:12:19.726 A:middle
and then continuously go
back through the stack

00:12:19.726 --> 00:12:20.766 A:middle
until we hit the bottom.

00:12:21.096 --> 00:12:22.236 A:middle
This is a backtrace.

00:12:22.886 --> 00:12:24.446 A:middle
If we take enough of
these and put them

00:12:24.446 --> 00:12:27.436 A:middle
in the call tree view you
can get a pretty good picture

00:12:27.436 --> 00:12:29.176 A:middle
of what's going on inside
of your application.

00:12:29.546 --> 00:12:32.166 A:middle
I want to point out,
the frame Pointers

00:12:32.306 --> 00:12:34.026 A:middle
on the stack are
absolutely required.

00:12:34.536 --> 00:12:38.256 A:middle
If you're compiling code
with fomit-frame-pointer turn

00:12:38.256 --> 00:12:40.966 A:middle
that off to try to do the
time type of profiling

00:12:40.966 --> 00:12:42.466 A:middle
that we're doing here.

00:12:43.116 --> 00:12:44.566 A:middle
Let's look at the
optimize cases.

00:12:44.566 --> 00:12:47.026 A:middle
This is where drawRect
was compiled

00:12:47.026 --> 00:12:48.396 A:middle
with compiler optimizations
enabled.

00:12:48.966 --> 00:12:51.166 A:middle
Same situation, we
have a drawRect frame.

00:12:51.166 --> 00:12:53.116 A:middle
We're about to call
into draw path.

00:12:54.086 --> 00:12:57.586 A:middle
You notice when draw path
returns drawRect is finished.

00:12:57.686 --> 00:12:58.766 A:middle
Doesn't need to do anything.

00:12:59.006 --> 00:13:00.256 A:middle
It is going to return.



00:12:59.006 --> 00:13:00.256 A:middle
It is going to return.

00:13:00.256 --> 00:13:03.056 A:middle
The way it returns, it is
it pops the stack frame,

00:13:03.476 --> 00:13:06.076 A:middle
restores the previous
value of the frame Pointer

00:13:06.506 --> 00:13:07.786 A:middle
and jumps back to the caller.

00:13:09.016 --> 00:13:11.176 A:middle
The compiler looks at
this and says well,

00:13:11.456 --> 00:13:17.146 A:middle
why does draw path need anything
from drawRect's stack frame.

00:13:18.406 --> 00:13:18.806 A:middle
It doesn't.

00:13:18.806 --> 00:13:20.886 A:middle
Furthermore, why come
in to drawRect --

00:13:20.886 --> 00:13:22.426 A:middle
back to drawRect at
all when it is going

00:13:22.426 --> 00:13:23.266 A:middle
to return to its caller?

00:13:23.966 --> 00:13:27.376 A:middle
What it does, it rearranges
the code like this.

00:13:27.676 --> 00:13:30.836 A:middle
It is going to pop the stack
frame, restore the frame Pointer

00:13:30.886 --> 00:13:34.076 A:middle
and make a direct call
back into draw path meaning

00:13:34.416 --> 00:13:36.026 A:middle
that we don't need to
jump back to the caller.

00:13:36.986 --> 00:13:39.706 A:middle
That's harder to explain
than it is to see.

00:13:39.706 --> 00:13:43.286 A:middle
Let's imagine what it would look
like when running this code.

00:13:43.616 --> 00:13:46.046 A:middle
We'll pop the stack frame off to
get rid of the local variables.

00:13:47.066 --> 00:13:49.346 A:middle
We'll restore the frame
Pointer to the original value

00:13:49.456 --> 00:13:50.856 A:middle
and the value of
the link register.

00:13:51.596 --> 00:13:55.676 A:middle
Then we'll jump to the beginning
of the code for draw path.

00:13:55.676 --> 00:13:57.916 A:middle
Draw path is going to
push its own frame back

00:13:57.916 --> 00:14:00.776 A:middle
on to the stack using
the value that it found



00:13:57.916 --> 00:14:00.776 A:middle
on to the stack using
the value that it found

00:14:00.776 --> 00:14:02.836 A:middle
in the link register
and the frame Pointer.

00:14:03.096 --> 00:14:06.266 A:middle
From draw path's perspective
it was called directly

00:14:06.266 --> 00:14:09.066 A:middle
from draw layer in
context from UIKit.

00:14:09.996 --> 00:14:11.626 A:middle
If we take a time
sample at this point,

00:14:12.136 --> 00:14:13.696 A:middle
we'll see the exact same story.

00:14:15.036 --> 00:14:16.966 A:middle
Even though that's not
the actual call sequence

00:14:16.966 --> 00:14:19.086 A:middle
that happened, this is
what the time profiler saw.

00:14:19.546 --> 00:14:22.966 A:middle
That's what we ended up
seeing in our call trees.

00:14:23.576 --> 00:14:25.996 A:middle
This is called Tail Call
Elimination, it is common

00:14:25.996 --> 00:14:31.046 A:middle
in highly optimized code
and has some benefits.

00:14:31.046 --> 00:14:31.966 A:middle
It saves stack memory.

00:14:32.796 --> 00:14:35.286 A:middle
In the process of saving stack
memory, it keeps the caches hot,

00:14:35.286 --> 00:14:39.436 A:middle
that reuses the memory,
the caches and data.

00:14:39.436 --> 00:14:42.766 A:middle
It has a profound
effect on recursive code,

00:14:42.806 --> 00:14:45.906 A:middle
especially tail call recursive
code, where a function

00:14:45.906 --> 00:14:48.346 A:middle
or method calls itself as the
last thing and then returns.

00:14:49.226 --> 00:14:53.436 A:middle
Without pushing those frames
a Tail Call Elimination inside

00:14:53.436 --> 00:14:56.406 A:middle
of a recursive function can
make the performance as good

00:14:56.406 --> 00:15:00.216 A:middle
as its iterative version, so
you don't get the stack growth



00:14:56.406 --> 00:15:00.216 A:middle
as its iterative version, so
you don't get the stack growth

00:15:00.216 --> 00:15:02.856 A:middle
and you get the high
performance as well.

00:15:02.856 --> 00:15:06.276 A:middle
This optimization leave on
with highly recursive code.

00:15:06.696 --> 00:15:09.156 A:middle
If you want to turn it off
for the sake of profiling

00:15:09.156 --> 00:15:13.536 A:middle
to show a cleaner stack trace
you can turn it off by going

00:15:13.536 --> 00:15:15.306 A:middle
in the build settings
of the project

00:15:15.786 --> 00:15:17.546 A:middle
and setting the compiler flag,

00:15:17.726 --> 00:15:20.646 A:middle
the CFLAGS to
FNO-optimize-sibling-calls,

00:15:20.856 --> 00:15:22.116 A:middle
turning off the optimization,

00:15:22.426 --> 00:15:24.736 A:middle
and unfortunately the
performance gains with it,

00:15:25.096 --> 00:15:28.876 A:middle
but you'll get a better
result in the time profiler.

00:15:28.876 --> 00:15:31.116 A:middle
If you choose to live with
it, and you want to identify

00:15:31.296 --> 00:15:34.796 A:middle
if a tail call is happening,
then what you can do,

00:15:34.796 --> 00:15:38.626 A:middle
you can look at the disassembly
and call sight of the last call.

00:15:39.476 --> 00:15:42.056 A:middle
If it is a normal call, it
is going to use a branch

00:15:42.056 --> 00:15:44.716 A:middle
and link family of instructions,
that's the first example there.

00:15:45.756 --> 00:15:47.606 A:middle
What that does, it jumps
to the new function

00:15:47.606 --> 00:15:50.126 A:middle
and saves the return value
in the link register.

00:15:51.316 --> 00:15:54.066 A:middle
If it is a tail call case and
we're going to jump directly

00:15:54.066 --> 00:15:59.166 A:middle
into the new function, it will
be a direct branch instruction.

00:15:59.236 --> 00:16:00.776 A:middle
Without the BL.



00:15:59.236 --> 00:16:00.776 A:middle
Without the BL.

00:16:00.926 --> 00:16:04.656 A:middle
That could be a call instruction
for a branch and link

00:16:04.716 --> 00:16:06.596 A:middle
and the branch would
be a jump instruction,

00:16:06.726 --> 00:16:10.576 A:middle
if you see that,
it looks similar.

00:16:10.656 --> 00:16:14.816 A:middle
Now it is up to Kris if he wants
to disable the optimization

00:16:14.816 --> 00:16:17.456 A:middle
and recompile, or he can
carry on, it is your choice.

00:16:18.396 --> 00:16:20.856 A:middle
&gt;&gt; KRIS MARKEL: I'll
look at the disassembly.

00:16:20.856 --> 00:16:24.936 A:middle
In Instruments, upper right-hand
corner of the detailed view,

00:16:24.936 --> 00:16:28.826 A:middle
there's a button, view
disassembly, if I click that,

00:16:28.826 --> 00:16:30.866 A:middle
I see the disassembly
for the method

00:16:31.076 --> 00:16:35.006 A:middle
and we can confirm the call to
context add path is a branch

00:16:35.006 --> 00:16:37.616 A:middle
and link, the call
to context draw path,

00:16:37.716 --> 00:16:39.176 A:middle
it is just a simple branch.

00:16:39.596 --> 00:16:42.676 A:middle
I'm confident that this is a
case of Tail Call Elimination

00:16:43.046 --> 00:16:48.466 A:middle
that 55% that I saw on the call
tree that was not attributed

00:16:48.466 --> 00:16:51.346 A:middle
to my drawRect should be
attributed to the drawRect.

00:16:51.836 --> 00:16:53.716 A:middle
That is good news.

00:16:53.826 --> 00:16:57.966 A:middle
I know now my drawRect is
on my heaviest deck frame,

00:16:58.026 --> 00:16:59.066 A:middle
my heaviest stack trace

00:16:59.456 --> 00:17:02.946 A:middle
and it is consuming
55 to 60% of my time.



00:16:59.456 --> 00:17:02.946 A:middle
and it is consuming
55 to 60% of my time.

00:17:03.016 --> 00:17:03.656 A:middle
This is great.

00:17:03.656 --> 00:17:04.715 A:middle
I know where to optimize.

00:17:04.886 --> 00:17:07.606 A:middle
I optimize drawRect,
I'm good to go.

00:17:08.465 --> 00:17:09.695 A:middle
Let's look at this drawRect.

00:17:11.215 --> 00:17:14.866 A:middle
Looking that the drawRect, if
I had a table I would flip it.

00:17:15.685 --> 00:17:17.955 A:middle
There is not much
to optimize here.

00:17:18.165 --> 00:17:20.276 A:middle
It is hard to think
of a simpler drawRect

00:17:20.736 --> 00:17:21.996 A:middle
that actually is functional.

00:17:22.175 --> 00:17:28.006 A:middle
We have 4 function calls,
context, you know, CG calls,

00:17:28.516 --> 00:17:30.596 A:middle
this drawRect really
does not do much.

00:17:30.996 --> 00:17:33.716 A:middle
It turns out that this is
actually a really common

00:17:33.716 --> 00:17:36.206 A:middle
occurrence when doing profiling.

00:17:36.646 --> 00:17:41.776 A:middle
You will take a look at
your hot spots and code,

00:17:42.046 --> 00:17:45.796 A:middle
there is not much you can
do in your code directly

00:17:46.006 --> 00:17:47.346 A:middle
to improve your performance.

00:17:48.056 --> 00:17:50.336 A:middle
You know, this junction,
what do you do?

00:17:50.336 --> 00:17:55.466 A:middle
You know, other than flipping
tables, crying into your pillow

00:17:55.466 --> 00:17:59.186 A:middle
at night, what we did was we
went through, started to look

00:17:59.186 --> 00:18:01.916 A:middle
at the core graphics
documentation and other drawing,



00:17:59.186 --> 00:18:01.916 A:middle
at the core graphics
documentation and other drawing,

00:18:01.916 --> 00:18:03.526 A:middle
you know, Cocoa drawing
documentation.

00:18:04.496 --> 00:18:07.076 A:middle
We came across this
particular property here.

00:18:07.936 --> 00:18:09.576 A:middle
This drawsAsynchrously.

00:18:10.136 --> 00:18:12.916 A:middle
Lo and behold, there was a
make my code faster button

00:18:13.046 --> 00:18:17.116 A:middle
that was created by
an Apple engineer.

00:18:19.076 --> 00:18:20.156 A:middle
This is excellent.

00:18:20.746 --> 00:18:23.146 A:middle
Above that, you see I copied

00:18:23.146 --> 00:18:25.906 A:middle
out of the documentation,
pasted it in there.

00:18:25.906 --> 00:18:27.456 A:middle
It says a couple of things
that are interesting.

00:18:27.456 --> 00:18:31.816 A:middle
It says, first of all, it may
improve performance, it may not.

00:18:31.816 --> 00:18:32.756 A:middle
You should always measure.

00:18:32.756 --> 00:18:35.756 A:middle
You know, okay, dad.

00:18:36.206 --> 00:18:37.126 A:middle
Let's measure.

00:18:37.306 --> 00:18:39.896 A:middle
Let's see if this
improves in performance.

00:18:40.386 --> 00:18:43.196 A:middle
This time to start the
Instruments, I'm just going

00:18:43.196 --> 00:18:45.316 A:middle
to do command-I for Instruments.

00:18:45.316 --> 00:18:46.766 A:middle
It will do the same thing.

00:18:47.356 --> 00:18:50.536 A:middle
It will build the application
and install on the device,

00:18:51.126 --> 00:18:52.306 A:middle
bring up the template chooser.

00:18:53.256 --> 00:18:54.366 A:middle
It takes a moment.

00:18:55.816 --> 00:18:56.926 A:middle
Two moments.

00:18:57.556 --> 00:18:58.946 A:middle
Three moments.

00:18:59.176 --> 00:19:00.396 A:middle
Here we go.



00:18:59.176 --> 00:19:00.396 A:middle
Here we go.

00:19:00.396 --> 00:19:02.856 A:middle
Another shortcut I like
to use, if you take a look

00:19:02.856 --> 00:19:04.316 A:middle
at the choose button down here.

00:19:04.956 --> 00:19:07.556 A:middle
If I hold down the option
button it changes to profile.

00:19:07.996 --> 00:19:09.856 A:middle
What it means, when
I click this,

00:19:10.156 --> 00:19:11.866 A:middle
the application is going
to start recording.

00:19:12.186 --> 00:19:13.776 A:middle
It saves me a step or two.

00:19:14.016 --> 00:19:15.046 A:middle
I'll do that now.

00:19:15.836 --> 00:19:18.636 A:middle
Now the time profiler
will come up.

00:19:19.076 --> 00:19:20.156 A:middle
This is measuring the app.

00:19:20.616 --> 00:19:22.536 A:middle
I'll do some quick
scrolling back

00:19:22.536 --> 00:19:24.296 A:middle
and forth, capturing some data.

00:19:24.296 --> 00:19:26.606 A:middle
I think that's enough.

00:19:26.606 --> 00:19:28.296 A:middle
Let's go ahead, stop
the recording.

00:19:28.776 --> 00:19:33.046 A:middle
I'm going to filter to
specifically the scrolling data.

00:19:33.496 --> 00:19:35.846 A:middle
If we go ahead down here
looking at the detailed view.

00:19:36.296 --> 00:19:37.696 A:middle
This is promising.

00:19:37.946 --> 00:19:40.706 A:middle
I'm actually -- you can see,
there is multiple threads here.

00:19:40.866 --> 00:19:42.206 A:middle
The threads are doing work.

00:19:42.696 --> 00:19:43.756 A:middle
That's really good.

00:19:43.846 --> 00:19:45.656 A:middle
If we go ahead, if
I hold down option,

00:19:45.986 --> 00:19:49.226 A:middle
click the disclosure triangle
I can see what the thread is

00:19:49.226 --> 00:19:52.126 A:middle
calling, there is
some dispatch calls,

00:19:52.126 --> 00:19:53.546 A:middle
some CG calls, that's good.

00:19:53.546 --> 00:19:54.636 A:middle
That's the drawing code.

00:19:55.186 --> 00:19:57.096 A:middle
We'll go ahead, check
the other one to see.

00:19:57.826 --> 00:19:59.226 A:middle
Hold down the option key.

00:19:59.886 --> 00:20:02.206 A:middle
Dispatch, CG calls.



00:19:59.886 --> 00:20:02.206 A:middle
Dispatch, CG calls.

00:20:02.506 --> 00:20:03.366 A:middle
This is good.

00:20:03.366 --> 00:20:04.736 A:middle
This is looking promising.

00:20:05.226 --> 00:20:09.156 A:middle
I'm multithreaded, in
theory my app is faster.

00:20:10.036 --> 00:20:13.946 A:middle
However, multithreading does
not necessarily mean faster.

00:20:13.946 --> 00:20:17.206 A:middle
We should confirm this is
actually doing anything for us.

00:20:18.006 --> 00:20:21.746 A:middle
One way to do that, I happen to
know this device is two CPUs,

00:20:22.136 --> 00:20:24.166 A:middle
if the CPUs operate in parallel

00:20:24.166 --> 00:20:28.746 A:middle
at max capacity I should
see a 200% CPU usage

00:20:29.096 --> 00:20:30.326 A:middle
in my graph up here.

00:20:31.126 --> 00:20:33.666 A:middle
I'm not seeing anything
over 100%, that's a bit

00:20:33.666 --> 00:20:36.286 A:middle
of a warning sign, it
doesn't necessarily mean

00:20:36.536 --> 00:20:38.646 A:middle
that they're not both doing
work at the same time.

00:20:39.046 --> 00:20:40.296 A:middle
It means that I need
to check further.

00:20:41.076 --> 00:20:42.016 A:middle
How do we check further?

00:20:42.676 --> 00:20:45.436 A:middle
Instruments has what we call
strategies, it is different ways

00:20:45.436 --> 00:20:47.326 A:middle
of partitioning the
data to look at them.

00:20:47.466 --> 00:20:48.406 A:middle
There is three of them.

00:20:48.836 --> 00:20:51.456 A:middle
The first one is the Instrument
strategies, the default,

00:20:51.646 --> 00:20:52.546 A:middle
we're looking at it here.

00:20:53.396 --> 00:20:55.286 A:middle
The second one is
the CPU strategy,

00:20:55.656 --> 00:20:58.916 A:middle
it shows the data per
CPU or CPU relevant data

00:20:59.816 --> 00:21:01.656 A:middle
and the final one is
the thread strategy.



00:20:59.816 --> 00:21:01.656 A:middle
and the final one is
the thread strategy.

00:21:01.966 --> 00:21:04.546 A:middle
It shows you details on
what each thread is doing.

00:21:05.386 --> 00:21:07.456 A:middle
Let's look at the CPU strategy.

00:21:07.456 --> 00:21:10.576 A:middle
We can see we have
each of the CPUs,

00:21:10.576 --> 00:21:12.626 A:middle
we can see how much
work it is doing.

00:21:12.626 --> 00:21:14.816 A:middle
At the bottom, we see
the combined usage.

00:21:15.176 --> 00:21:21.986 A:middle
A nice thing to do here, when I
zoom in far enough, the details,

00:21:22.046 --> 00:21:24.236 A:middle
what the graph shows me,
it will actually change.

00:21:25.016 --> 00:21:28.336 A:middle
Rather than show making the
average usage, it will show

00:21:28.336 --> 00:21:30.386 A:middle
if the CPU is active or not,

00:21:30.386 --> 00:21:32.796 A:middle
it will go from average
usage, to either on or off.

00:21:33.386 --> 00:21:36.016 A:middle
Now each CPU shows an
on state or off state,

00:21:36.016 --> 00:21:37.146 A:middle
whether or not it is working.

00:21:37.846 --> 00:21:41.566 A:middle
What you notice here, the
CPUs are never working

00:21:41.566 --> 00:21:44.426 A:middle
at the same time, there
is no parallelism here.

00:21:44.786 --> 00:21:48.656 A:middle
You know, this is not good.

00:21:49.276 --> 00:21:53.136 A:middle
If we want to feel worse, we
look at the thread strategy.

00:21:54.186 --> 00:21:56.166 A:middle
What this is showing
us, each icon,

00:21:56.166 --> 00:22:00.226 A:middle
it represents a sample
the time profiler took,



00:21:56.166 --> 00:22:00.226 A:middle
it represents a sample
the time profiler took,

00:22:00.226 --> 00:22:01.376 A:middle
you can click on it.

00:22:01.376 --> 00:22:02.206 A:middle
See the call stack.

00:22:02.626 --> 00:22:04.756 A:middle
Here this is on a
background thread

00:22:04.756 --> 00:22:08.246 A:middle
and you see the core graphics
calls, here is the main thread,

00:22:08.246 --> 00:22:14.666 A:middle
you see the main -- the work
we're doing on the main thread.

00:22:15.206 --> 00:22:17.216 A:middle
As you see, if I zoom
in to the right level,

00:22:17.216 --> 00:22:18.986 A:middle
it is probably here,
I scroll around,

00:22:19.336 --> 00:22:22.426 A:middle
you see there is
not really anywhere

00:22:22.426 --> 00:22:24.596 A:middle
where two threads are
working at the same time.

00:22:24.816 --> 00:22:27.326 A:middle
It is jumping from
one thread to another.

00:22:28.696 --> 00:22:34.356 A:middle
So the drawsAsynchronously, this
has not really done anything

00:22:34.356 --> 00:22:38.036 A:middle
for us, in theory, it
may have slowed us down.

00:22:38.036 --> 00:22:42.426 A:middle
Now not only we doing the same
drawing work but also managing,

00:22:42.426 --> 00:22:45.096 A:middle
you know, core graphics system
managed the threads it is

00:22:45.096 --> 00:22:47.926 A:middle
working on, that sort of thing.

00:22:47.926 --> 00:22:48.756 A:middle
That didn't really help.

00:22:49.916 --> 00:22:51.726 A:middle
I'll turn it off.

00:22:51.866 --> 00:22:56.166 A:middle
I'll flip another table I guess.

00:22:56.246 --> 00:22:59.776 A:middle
It is not clear, the
magic button didn't help.



00:23:00.556 --> 00:23:01.696 A:middle
What do we do now?

00:23:02.396 --> 00:23:04.726 A:middle
This is a really
common occurrence again

00:23:04.726 --> 00:23:05.496 A:middle
in time profiling.

00:23:06.336 --> 00:23:08.756 A:middle
You try lots of things,
most don't work.

00:23:09.496 --> 00:23:11.626 A:middle
We step back.

00:23:11.876 --> 00:23:12.716 A:middle
What does the app do?

00:23:13.076 --> 00:23:15.136 A:middle
It builds a path
and draws a path.

00:23:15.956 --> 00:23:17.446 A:middle
We have seen the draw path code.

00:23:17.446 --> 00:23:19.666 A:middle
Let's think about
the build path code.

00:23:19.936 --> 00:23:23.466 A:middle
That's right in here.

00:23:24.086 --> 00:23:26.316 A:middle
What we wanted to do, we wanted

00:23:26.316 --> 00:23:29.116 A:middle
to investigate the actual
path we're building.

00:23:29.636 --> 00:23:32.616 A:middle
What this code does, it
loops the data elements,

00:23:32.886 --> 00:23:35.036 A:middle
creating a path and
adds a line to that path

00:23:35.036 --> 00:23:35.936 A:middle
for each data element.

00:23:36.236 --> 00:23:39.386 A:middle
We want to know how many lines
we're adding to the path.

00:23:39.386 --> 00:23:42.106 A:middle
This is something that the
time profiler can't tell us.

00:23:42.416 --> 00:23:44.296 A:middle
It can't tell you how long,

00:23:44.566 --> 00:23:46.356 A:middle
or how many times
a particular method

00:23:46.356 --> 00:23:47.536 A:middle
or function has been called.

00:23:47.536 --> 00:23:49.936 A:middle
It doesn't know the difference

00:23:49.936 --> 00:23:52.296 A:middle
between a slow function
that's called a few times

00:23:52.296 --> 00:23:54.716 A:middle
or a fast function
that's called a lot.

00:23:54.716 --> 00:23:58.386 A:middle
In this case we resorted to
NSLog and we just have a thing,

00:23:58.386 --> 00:24:01.346 A:middle
every time we add a path
we increment our counter



00:23:58.386 --> 00:24:01.346 A:middle
every time we add a path
we increment our counter

00:24:01.346 --> 00:24:05.666 A:middle
and then we log it when
we're done with the loop.

00:24:05.666 --> 00:24:07.886 A:middle
Something important
to point out, NSLog,

00:24:08.416 --> 00:24:10.626 A:middle
it is not a very fast function.

00:24:11.166 --> 00:24:13.406 A:middle
You don't want it in
high performance code.

00:24:13.406 --> 00:24:16.076 A:middle
You probably don't want to
use it for anything other

00:24:16.076 --> 00:24:18.816 A:middle
than gathering diagnostic
information or debugging.

00:24:19.386 --> 00:24:21.776 A:middle
When you're done,
delete it from the code.

00:24:21.776 --> 00:24:24.736 A:middle
In this case we just comment
it out so you can see it.

00:24:25.066 --> 00:24:29.636 A:middle
What we have found, we're
adding 10,000 lines to the point

00:24:30.206 --> 00:24:32.616 A:middle
in cases where we did
not need to do that.

00:24:32.616 --> 00:24:33.866 A:middle
In fact, there is no way

00:24:33.866 --> 00:24:36.956 A:middle
to display 10,000
lines on this device.

00:24:37.096 --> 00:24:39.026 A:middle
Especially when you're
zoomed out far enough

00:24:39.026 --> 00:24:41.676 A:middle
that all the data fits
within 100 screen points.

00:24:41.716 --> 00:24:44.356 A:middle
There is no reason to draw
10,000 lines in there.

00:24:44.356 --> 00:24:47.746 A:middle
We need to draw 100 lines.

00:24:47.966 --> 00:24:48.946 A:middle
It is a lot less work.

00:24:49.936 --> 00:24:54.136 A:middle
We went ahead, we created an
implementation that did that.

00:24:54.296 --> 00:24:58.306 A:middle
If multiple data
elements, data points are

00:24:58.306 --> 00:25:01.386 A:middle
within a single screen
point it just finds the max



00:24:58.306 --> 00:25:01.386 A:middle
within a single screen
point it just finds the max

00:25:01.436 --> 00:25:02.686 A:middle
and draws a single line.

00:25:03.146 --> 00:25:07.336 A:middle
If we're using 100 screen points
we're creating 100 screen lines.

00:25:08.396 --> 00:25:11.386 A:middle
We'll go ahead and switch
to that implementation.

00:25:12.306 --> 00:25:14.496 A:middle
. . We're feeling
good about that.

00:25:14.576 --> 00:25:18.386 A:middle
We'll change the element
count up to the goal

00:25:18.386 --> 00:25:20.616 A:middle
of 100,000 rather than 10,000.

00:25:21.476 --> 00:25:25.796 A:middle
We'll see if that
helped us at all.

00:25:25.796 --> 00:25:29.626 A:middle
I'll use command-I to
start up the Instruments.

00:25:30.016 --> 00:25:31.926 A:middle
Since Instruments is already
open, it is just going

00:25:31.926 --> 00:25:35.366 A:middle
to bring it to the foreground
and start recording immediately.

00:25:35.366 --> 00:25:36.976 A:middle
Here we go.

00:25:37.076 --> 00:25:38.856 A:middle
A new recording.

00:25:39.556 --> 00:25:43.236 A:middle
We'll go ahead and scroll,
the scrolling seems fine.

00:25:44.486 --> 00:25:45.836 A:middle
I'll zoom out.

00:25:46.746 --> 00:25:49.216 A:middle
Zooming performance
is much, much better.

00:25:49.396 --> 00:25:52.136 A:middle
It takes longer because I
have more data to zoom out.

00:25:52.846 --> 00:25:54.056 A:middle
It is actually looking
pretty good.

00:25:54.896 --> 00:25:56.686 A:middle
I'm going to do the
swiping back and forth.

00:25:56.686 --> 00:25:59.236 A:middle
It is tracking my
finger really well now.

00:25:59.726 --> 00:26:02.696 A:middle
It is actually keeping up with
it, doing a fantastic job.



00:25:59.726 --> 00:26:02.696 A:middle
It is actually keeping up with
it, doing a fantastic job.

00:26:04.046 --> 00:26:07.266 A:middle
Hooray! All done!

00:26:07.606 --> 00:26:11.036 A:middle
Except not quite.

00:26:11.036 --> 00:26:12.336 A:middle
If we look at the actual amount

00:26:12.386 --> 00:26:15.106 A:middle
of CPU we're using while
scrolling back and forth,

00:26:15.106 --> 00:26:18.416 A:middle
we can see, you know,
sometimes it is down to 60%,

00:26:18.416 --> 00:26:20.186 A:middle
it is usually in the 70s or 80s.

00:26:21.046 --> 00:26:23.956 A:middle
Technically we're meeting
our performance goals.

00:26:24.566 --> 00:26:26.986 A:middle
What are we doing --
what's the next thing to do

00:26:26.986 --> 00:26:28.716 A:middle
with this app or prototype?

00:26:28.716 --> 00:26:30.606 A:middle
We'll add additional features.

00:26:31.176 --> 00:26:36.266 A:middle
We know that we need more
headroom than what we have here.

00:26:36.766 --> 00:26:42.036 A:middle
How do we make it faster,
how do we make the app better

00:26:42.036 --> 00:26:44.346 A:middle
and meet performance goals?

00:26:45.416 --> 00:26:46.936 A:middle
We'll focus on this.

00:26:47.426 --> 00:26:50.156 A:middle
We'll filter to that data.

00:26:50.156 --> 00:26:52.576 A:middle
I'll give myself a little room.

00:26:53.196 --> 00:26:55.266 A:middle
In this case, I'm going to
hold down the option key

00:26:56.246 --> 00:26:57.996 A:middle
and click main and
expand this out.

00:26:58.076 --> 00:27:02.206 A:middle
I can actually go down here
and I can see this method here.



00:26:58.076 --> 00:27:02.206 A:middle
I can actually go down here
and I can see this method here.

00:27:02.876 --> 00:27:06.566 A:middle
You know, now that the drawing
of the paths is fast enough,

00:27:06.566 --> 00:27:09.976 A:middle
it is the building of the path
that becomes the bottleneck.

00:27:09.976 --> 00:27:14.716 A:middle
I want to focus on this method.

00:27:15.046 --> 00:27:17.456 A:middle
I will click the focus button.

00:27:17.456 --> 00:27:21.736 A:middle
That just moves aside
everything outside of the method

00:27:21.736 --> 00:27:29.126 A:middle
and normalizes our percentages
to within this method.

00:27:29.126 --> 00:27:33.596 A:middle
This method is spending 55% of
time in the get next element

00:27:34.206 --> 00:27:38.876 A:middle
and 10, 11% of time
in objc msgSend.

00:27:39.566 --> 00:27:43.306 A:middle
Something that I
know, objc msgSend,

00:27:43.306 --> 00:27:45.326 A:middle
it is a super fast method.

00:27:45.326 --> 00:27:46.746 A:middle
It is super optimized.

00:27:47.126 --> 00:27:52.726 A:middle
But, if I can get that
10% back, I want it.

00:27:52.726 --> 00:27:59.136 A:middle
If we look inside of our code
here we can see it is actually

00:27:59.136 --> 00:27:59.686 A:middle
very clear.

00:27:59.686 --> 00:28:03.396 A:middle
Most of our time is spent
on getting the next element.



00:27:59.686 --> 00:28:03.396 A:middle
Most of our time is spent
on getting the next element.

00:28:04.086 --> 00:28:06.896 A:middle
This percentage here, it is a
bit higher than in the tree view

00:28:07.126 --> 00:28:10.436 A:middle
because it includes
the objc msgSend time.

00:28:10.436 --> 00:28:14.806 A:middle
If I get rid of that and
make this iterator faster,

00:28:15.126 --> 00:28:19.366 A:middle
I hopefully can get the
performance boost that I want.

00:28:19.616 --> 00:28:26.406 A:middle
To give us ideas on how much
to do that, it is back to Chad.

00:28:26.526 --> 00:28:31.996 A:middle
&gt;&gt; CHAD WOOLF: Let's talk
about objc msgSend a bit.

00:28:31.996 --> 00:28:35.286 A:middle
It implicitly gets inserted

00:28:35.346 --> 00:28:37.966 A:middle
by the compiler whenever you
use the square bracket notation

00:28:38.566 --> 00:28:40.136 A:middle
or whenever you use
the dot notation

00:28:40.136 --> 00:28:41.836 A:middle
to access a property
on an object.

00:28:43.166 --> 00:28:46.016 A:middle
Its purpose is to look up
the method implementation

00:28:46.016 --> 00:28:48.646 A:middle
for the selector and
invoke that method.

00:28:49.026 --> 00:28:51.586 A:middle
That's a long way of saying
that's how we do dynamic

00:28:51.616 --> 00:28:52.806 A:middle
dispatch in Objective-C.

00:28:54.086 --> 00:28:59.146 A:middle
Objc msgSend is extremely fast
and does not push a stack frame.

00:28:59.786 --> 00:29:02.366 A:middle
When you look at
your time profiles,



00:28:59.786 --> 00:29:02.366 A:middle
When you look at
your time profiles,

00:29:02.576 --> 00:29:04.306 A:middle
you typically won't
see its effect.

00:29:05.426 --> 00:29:08.636 A:middle
The times that you do see it
would be a perfect example

00:29:08.636 --> 00:29:11.536 A:middle
like we have where we
see it in our iterator.

00:29:11.536 --> 00:29:15.126 A:middle
What we're doing, we're
iterating over 100,000 points

00:29:15.126 --> 00:29:19.406 A:middle
and calling it the get next
method with a small method body.

00:29:19.406 --> 00:29:21.436 A:middle
Just increments a couple
values and returns a structure.

00:29:22.676 --> 00:29:26.266 A:middle
What's happening, all
of that overhead time

00:29:26.266 --> 00:29:29.066 A:middle
from the Objective-C
message send is accumulating

00:29:29.066 --> 00:29:31.716 A:middle
into something that's
measurable.

00:29:31.716 --> 00:29:36.196 A:middle
Is there a way to get
around that overhead?

00:29:36.466 --> 00:29:38.866 A:middle
Not exactly.

00:29:38.866 --> 00:29:41.166 A:middle
Objective-C by design
is a dynamic language,

00:29:41.586 --> 00:29:43.856 A:middle
you have to make the
objc msgSend call

00:29:44.116 --> 00:29:47.446 A:middle
when accessing methods
for objects and classes.

00:29:48.246 --> 00:29:52.046 A:middle
It does this every time
because you can switch

00:29:52.046 --> 00:29:53.506 A:middle
out method implementations
at runtime.

00:29:54.156 --> 00:29:57.676 A:middle
There is no compile time in
Objective-C saying I want

00:29:57.676 --> 00:29:59.516 A:middle
to call in this particular
method body.

00:29:59.856 --> 00:30:04.506 A:middle
The only exception here, if you
do what's called method caching,



00:29:59.856 --> 00:30:04.506 A:middle
The only exception here, if you
do what's called method caching,

00:30:04.906 --> 00:30:07.306 A:middle
where you look up the method
implementation yourself

00:30:07.786 --> 00:30:09.556 A:middle
and you call it through
its function Pointer.

00:30:09.806 --> 00:30:13.816 A:middle
In general I don't
recommend that you do that.

00:30:13.816 --> 00:30:15.266 A:middle
It is fragile as
you can imagine.

00:30:15.766 --> 00:30:18.996 A:middle
In general, in my experience
it hasn't given me the kind

00:30:18.996 --> 00:30:21.716 A:middle
of performance wins I'm
expecting because you got

00:30:21.856 --> 00:30:23.746 A:middle
to think about why we're
here in the first place.

00:30:24.136 --> 00:30:27.026 A:middle
The reason we're here, the
get next element method has

00:30:27.026 --> 00:30:28.016 A:middle
that small method body.

00:30:28.716 --> 00:30:31.586 A:middle
Even if you invoke it through
the function Pointer you still

00:30:31.586 --> 00:30:34.256 A:middle
have to have to marshal the
arguments and push the frames

00:30:34.256 --> 00:30:35.926 A:middle
on to the stack and pop
them when you're done.

00:30:36.806 --> 00:30:38.766 A:middle
That's exactly what you saw
in the previous set of slides,

00:30:38.926 --> 00:30:40.286 A:middle
that can be a lot of overhead

00:30:40.286 --> 00:30:42.126 A:middle
with an increment
and then return.

00:30:42.546 --> 00:30:47.826 A:middle
I want to make sure I point it
out that method caching is not

00:30:47.826 --> 00:30:50.906 A:middle
as fast as inlining, what we
really want in this case is

00:30:50.906 --> 00:30:53.116 A:middle
that small method
body to be inlined.

00:30:54.486 --> 00:30:55.886 A:middle
How do you that in Objective-C?

00:30:57.246 --> 00:30:59.046 A:middle
Well, you have alternatives.

00:30:59.166 --> 00:31:01.466 A:middle
The first one, you
could have used C



00:30:59.166 --> 00:31:01.466 A:middle
The first one, you
could have used C

00:31:02.406 --> 00:31:04.436 A:middle
and you could have
used structures instead

00:31:04.436 --> 00:31:06.856 A:middle
of an iterator, you
could pass a C ray

00:31:06.856 --> 00:31:07.986 A:middle
into the method for example.

00:31:08.416 --> 00:31:13.966 A:middle
If you want that OO
flavor you can use C++.

00:31:14.286 --> 00:31:16.156 A:middle
The way you use C++
in Objective-C,

00:31:16.156 --> 00:31:18.436 A:middle
is you rename the file
from a .m to a .mm

00:31:18.436 --> 00:31:20.726 A:middle
and then you can use C++ syntax.

00:31:21.446 --> 00:31:23.176 A:middle
Because Arc is usually
on by default,

00:31:23.366 --> 00:31:26.296 A:middle
then you take Objective-C
objects and put them

00:31:26.296 --> 00:31:29.896 A:middle
in STL containers, and put
them in instance variables

00:31:29.896 --> 00:31:32.016 A:middle
on your classes and structures.

00:31:33.136 --> 00:31:37.226 A:middle
This is handy and you get the
performance benefits of C++

00:31:37.306 --> 00:31:40.326 A:middle
and I have used it extensively
in Instruments to get

00:31:40.326 --> 00:31:43.126 A:middle
as much speed as I could
out of the track view

00:31:43.126 --> 00:31:45.256 A:middle
and other critical
areas of Instruments.

00:31:46.026 --> 00:31:49.676 A:middle
I know from firsthand experience
also there is a major downside

00:31:49.676 --> 00:31:50.116 A:middle
to this.

00:31:50.336 --> 00:31:54.146 A:middle
That is that you have to know
ahead of time which parts

00:31:54.146 --> 00:31:56.776 A:middle
of your code are going
to benefit from C++

00:31:57.306 --> 00:31:59.826 A:middle
and which codes will
benefit from Objective-C?



00:32:00.496 --> 00:32:02.966 A:middle
Sometimes, until
you're doing profiling,

00:32:03.166 --> 00:32:05.826 A:middle
you can make a mistake there
as we did in the demo case.

00:32:06.236 --> 00:32:07.526 A:middle
We wrote our iterator

00:32:07.646 --> 00:32:10.396 A:middle
in Objective-C not
realizing it would show

00:32:10.396 --> 00:32:11.846 A:middle
up in our time profiles.

00:32:12.896 --> 00:32:17.486 A:middle
Is there a better alternative
than what I just mentioned here?

00:32:18.996 --> 00:32:22.586 A:middle
There is. You knew
it was coming.

00:32:26.586 --> 00:32:30.846 A:middle
Swift is ideal, because unlike
Objective-C it is only dynamic

00:32:30.846 --> 00:32:32.766 A:middle
when it notes to be.

00:32:32.766 --> 00:32:36.026 A:middle
If you make sure that the
performance critical classes are

00:32:36.076 --> 00:32:39.756 A:middle
internal and you use
whole module optimization,

00:32:39.866 --> 00:32:43.136 A:middle
the compiler or the whole
tool chain can determine

00:32:43.426 --> 00:32:45.186 A:middle
when there's only one
method implementation

00:32:45.416 --> 00:32:49.376 A:middle
and inlines it right into
the call site giving you some

00:32:49.376 --> 00:32:52.926 A:middle
significant wins especially
on the iterator case.

00:32:53.606 --> 00:32:56.716 A:middle
Because we're prototyping,
rewriting the iterator

00:32:56.716 --> 00:33:00.426 A:middle
in the View Controller
in Swift is easy.



00:32:56.716 --> 00:33:00.426 A:middle
in the View Controller
in Swift is easy.

00:33:00.426 --> 00:33:03.206 A:middle
Kris has done that.

00:33:03.826 --> 00:33:09.636 A:middle
&gt;&gt; KRIS MARKEL: I have a Swift
implementation ready to go,

00:33:10.046 --> 00:33:14.886 A:middle
this is an easy port of the
Objective-C implementation

00:33:14.886 --> 00:33:19.856 A:middle
with a couple of the
suggestions they made

00:33:19.856 --> 00:33:22.276 A:middle
in this morning's session
about improving Swift code,

00:33:22.426 --> 00:33:24.816 A:middle
specifically turning on
whole module optimization.

00:33:25.496 --> 00:33:27.236 A:middle
Let's profile this.

00:33:27.236 --> 00:33:28.346 A:middle
Command-I.

00:33:29.076 --> 00:33:29.756 A:middle
It will build.

00:33:30.706 --> 00:33:33.466 A:middle
Install to the device.

00:33:34.086 --> 00:33:36.336 A:middle
It should just start profiling.

00:33:36.976 --> 00:33:42.206 A:middle
Okay. I'm going to bring
the application forward

00:33:42.206 --> 00:33:42.836 A:middle
so you can see.

00:33:44.136 --> 00:33:45.286 A:middle
Here is the scrolling.

00:33:45.916 --> 00:33:47.056 A:middle
Looking good.

00:33:48.286 --> 00:33:49.166 A:middle
Zooming out.

00:33:49.706 --> 00:33:51.286 A:middle
There you go.

00:33:51.926 --> 00:33:52.726 A:middle
Zooming out.

00:33:53.026 --> 00:33:54.206 A:middle
Staying nice and fast.

00:33:54.366 --> 00:33:57.476 A:middle
A lot of data to zoom out of.

00:33:57.686 --> 00:34:01.976 A:middle
Now, if I go ahead, move back
and forth, it moves really fast.



00:33:57.686 --> 00:34:01.976 A:middle
Now, if I go ahead, move back
and forth, it moves really fast.

00:34:02.031 --> 00:34:04.031 A:middle
[Applause]

00:34:04.046 --> 00:34:07.796 A:middle
&gt;&gt; KRIS MARKEL: It is very nice.

00:34:07.796 --> 00:34:10.045 A:middle
Thanks. Actually we can
go ahead in here and look

00:34:10.045 --> 00:34:11.396 A:middle
at what the CPU usage is.

00:34:11.826 --> 00:34:15.156 A:middle
You know, we've got,
actually further improvement

00:34:15.156 --> 00:34:19.295 A:middle
than what we expected, we're
expecting 5, 6% improvement

00:34:19.295 --> 00:34:23.786 A:middle
from removing the objc msgSend,
this is lower and I can actually

00:34:23.936 --> 00:34:27.726 A:middle
if I turn down this disclosure
triangle you see the two runs

00:34:27.726 --> 00:34:31.556 A:middle
next to each other and you see
the previous run in the lower --

00:34:31.966 --> 00:34:37.025 A:middle
the current run, it
is clearly much lower.

00:34:37.656 --> 00:34:39.585 A:middle
Actually if I go
ahead, I go in here,

00:34:39.585 --> 00:34:44.255 A:middle
I look for my build path method
I have to search for it now, oh,

00:34:44.386 --> 00:34:45.666 A:middle
that's not how you do a search.

00:34:46.106 --> 00:34:50.406 A:middle
If I hit command-F, it will
bring up this dialogue here.

00:34:50.406 --> 00:34:58.886 A:middle
I can type in build path and
it shows me my method here.

00:34:59.966 --> 00:35:03.666 A:middle
If we look at this, you
see here is my Swift code.



00:34:59.966 --> 00:35:03.666 A:middle
If we look at this, you
see here is my Swift code.

00:35:04.216 --> 00:35:07.666 A:middle
My get next call
which is right here,

00:35:07.666 --> 00:35:09.746 A:middle
it isn't showing
up in any samples.

00:35:09.746 --> 00:35:16.226 A:middle
You know, no samples
landed on this.

00:35:16.226 --> 00:35:19.046 A:middle
Why? It is because Swift
was able to inline it,

00:35:19.836 --> 00:35:22.436 A:middle
whip means that there's
no function overhead,

00:35:22.436 --> 00:35:24.056 A:middle
no method call overhead
whatsoever.

00:35:24.486 --> 00:35:28.696 A:middle
Because the code for the
iterator is inline with the rest

00:35:28.696 --> 00:35:32.116 A:middle
of the code it makes further
improvements explaining the

00:35:32.116 --> 00:35:35.346 A:middle
better performance
than what we hoped

00:35:35.346 --> 00:35:39.306 A:middle
for by skipping the
dynamic dispatch.

00:35:39.676 --> 00:35:42.036 A:middle
Chad, anything else to
tell these nice people?

00:35:42.616 --> 00:35:44.866 A:middle
&gt;&gt; CHAD WOOLF: We
have 5 minutes!

00:35:45.506 --> 00:35:47.586 A:middle
Of course I do.

00:35:47.586 --> 00:35:50.766 A:middle
Some tips for you to explore
Instruments on your own.

00:35:51.376 --> 00:35:55.726 A:middle
The first one to point out,
under the recording settings,

00:35:56.176 --> 00:35:57.626 A:middle
it's called record
waiting threads.

00:35:57.756 --> 00:35:59.286 A:middle
I mentioned that the service

00:35:59.286 --> 00:36:00.926 A:middle
and kernel we use
samples the active CPUs



00:35:59.286 --> 00:36:00.926 A:middle
and kernel we use
samples the active CPUs

00:36:00.926 --> 00:36:04.116 A:middle
but if you have threads sitting
around, blocked on a lock

00:36:04.116 --> 00:36:07.146 A:middle
or waiting for I/O, you
check this checkbox,

00:36:07.476 --> 00:36:09.736 A:middle
and the service will sample
the idle threads as well.

00:36:10.366 --> 00:36:12.156 A:middle
If you have code
that's contending

00:36:12.156 --> 00:36:14.736 A:middle
over a lock you see
the hot pods show

00:36:15.146 --> 00:36:17.726 A:middle
up when you enable
record waiting threads.

00:36:18.946 --> 00:36:20.796 A:middle
Another thing that
I find interesting,

00:36:21.456 --> 00:36:25.886 A:middle
in the display settings,
in the call tree section,

00:36:25.986 --> 00:36:27.396 A:middle
it is invert call tree.

00:36:28.686 --> 00:36:32.226 A:middle
Figuratively what it does, it
flips the call tree upside down.

00:36:32.226 --> 00:36:36.086 A:middle
Instead of seeing the leafs at
the bottom nodes of the tree,

00:36:36.186 --> 00:36:37.746 A:middle
that's functions that
don't call into anything,

00:36:38.106 --> 00:36:38.976 A:middle
they appear at the top.

00:36:39.296 --> 00:36:42.286 A:middle
If a utility function is
being called from 5, 6 places,

00:36:42.636 --> 00:36:46.606 A:middle
you invert that call tree to
see who is actually calling

00:36:46.806 --> 00:36:48.376 A:middle
into that particular function.

00:36:48.536 --> 00:36:50.016 A:middle
It gives you a different
perspective

00:36:50.016 --> 00:36:51.226 A:middle
on the data in the call tree.

00:36:51.986 --> 00:36:53.856 A:middle
When you right click a
node in the call tree,

00:36:54.556 --> 00:36:58.066 A:middle
you get a context menu and
there is interesting stuff

00:36:58.066 --> 00:36:58.846 A:middle
under there as well.

00:36:59.076 --> 00:37:03.116 A:middle
One thing that I use from time
to time is the charge to caller,



00:36:59.076 --> 00:37:03.116 A:middle
One thing that I use from time
to time is the charge to caller,

00:37:03.436 --> 00:37:04.996 A:middle
so what you can do, you
can charge a function

00:37:04.996 --> 00:37:06.436 A:middle
on method to the caller.

00:37:07.036 --> 00:37:10.136 A:middle
You can charge an entire Library
of Framework to the caller.

00:37:11.066 --> 00:37:14.546 A:middle
There's an option in there
as well to prune a subtree.

00:37:14.736 --> 00:37:16.896 A:middle
You don't want to work on a
specific problem at the time,

00:37:16.896 --> 00:37:19.966 A:middle
you can prune that out
of the data and focus

00:37:19.966 --> 00:37:23.496 A:middle
on what you want to focus on.

00:37:23.496 --> 00:37:26.116 A:middle
What did we learn?

00:37:26.116 --> 00:37:28.616 A:middle
Through all of this,
the first things I want

00:37:28.836 --> 00:37:29.576 A:middle
to remind you about,

00:37:29.906 --> 00:37:32.346 A:middle
is to incorporate
performance targets early.

00:37:33.376 --> 00:37:35.496 A:middle
If you're doing a big
performance rewrite

00:37:35.496 --> 00:37:38.886 A:middle
like we were, start with a
budget and keep monitoring it

00:37:38.886 --> 00:37:41.476 A:middle
because once you start layering
a lot of code on top of that,

00:37:41.476 --> 00:37:42.976 A:middle
it is harder to change.

00:37:44.426 --> 00:37:45.506 A:middle
Secondly, always measure.

00:37:45.816 --> 00:37:46.076 A:middle
Through all

00:37:46.076 --> 00:37:48.456 A:middle
of our demonstrations we
were taking time profiles

00:37:48.456 --> 00:37:52.136 A:middle
with the time profiler, we used
that data to find the hot spots

00:37:52.136 --> 00:37:54.596 A:middle
and retuning it,
by the end we had a

00:37:54.596 --> 00:37:56.076 A:middle
well-performing application.

00:37:56.626 --> 00:38:00.666 A:middle
If you go in blind, depends,
you may be lucky, hit it.



00:37:56.626 --> 00:38:00.666 A:middle
If you go in blind, depends,
you may be lucky, hit it.

00:38:01.086 --> 00:38:03.486 A:middle
I would start with a measurement
and go after that first.

00:38:03.976 --> 00:38:07.326 A:middle
In the third one, this
is most important to me,

00:38:07.326 --> 00:38:09.036 A:middle
I want to encourage
you to keep digging.

00:38:09.796 --> 00:38:11.596 A:middle
Some of these performance
problems you look

00:38:11.596 --> 00:38:13.826 A:middle
at at first may have
seemed impassable,

00:38:13.826 --> 00:38:16.806 A:middle
you say that's happening
in someone else's code

00:38:16.806 --> 00:38:18.356 A:middle
or a side effect of the runtime.

00:38:19.176 --> 00:38:22.166 A:middle
The reason we gave you the
details on the time profiler,

00:38:22.166 --> 00:38:24.936 A:middle
the runtimer, what the
disassembly view looks like,

00:38:25.496 --> 00:38:27.826 A:middle
is we wanted to show you
there is a whole world

00:38:27.826 --> 00:38:29.186 A:middle
out there of more details.

00:38:29.456 --> 00:38:33.226 A:middle
By using that, you can solve
the performance problems

00:38:33.226 --> 00:38:34.416 A:middle
that we were solving today.

00:38:34.986 --> 00:38:38.606 A:middle
I encourage you to keep
digging, and with creativity,

00:38:38.846 --> 00:38:40.856 A:middle
going out there into
sessions like this,

00:38:40.996 --> 00:38:42.866 A:middle
I know you guys will
be able to fix

00:38:42.976 --> 00:38:44.516 A:middle
and hit the performance
targets you want.

00:38:45.036 --> 00:38:49.386 A:middle
That just about does
it for today.

00:38:49.386 --> 00:38:52.606 A:middle
Stefan Lesser is our
dev tools evangelist,

00:38:52.606 --> 00:38:54.856 A:middle
contact him if you
have any questions.

00:38:55.756 --> 00:39:00.626 A:middle
We related sessions, Energy
debugging issues, turns out that



00:38:55.756 --> 00:39:00.626 A:middle
We related sessions, Energy
debugging issues, turns out that

00:39:00.956 --> 00:39:03.676 A:middle
if you have efficient code on
the CPU it uses less energy.

00:39:03.676 --> 00:39:05.836 A:middle
There was that session
on Wednesday.

00:39:06.396 --> 00:39:09.926 A:middle
Also tomorrow, there is
performance on iOS and Watch OS,

00:39:10.296 --> 00:39:13.276 A:middle
good news, the time profiler
can target apps on the watch.

00:39:13.346 --> 00:39:13.766 A:middle
That's a big boon.

00:39:13.766 --> 00:39:15.106 A:middle
Tomorrow we'll be in
labs from 9:00 to 2:00.

00:39:15.136 --> 00:39:15.976 A:middle
Enjoy the rest of
your conference.

00:39:16.016 --> 00:39:18.000 A:middle
[Applause]

