
00:00:25.516 --> 00:00:32.766 A:middle
[Applause]

00:00:33.266 --> 00:00:36.246 A:middle
&gt;&gt; Good morning, and welcome to
Optimizing Swift Performance.

00:00:36.546 --> 00:00:39.676 A:middle
My name is Nadav, and together
with my colleagues, Michael

00:00:39.836 --> 00:00:41.836 A:middle
and Joe, I am going
to show you how

00:00:41.836 --> 00:00:43.456 A:middle
to optimize your Swift programs.

00:00:44.356 --> 00:00:48.626 A:middle
Now, we, the engineers on the
Compiler Team, are passionate

00:00:48.626 --> 00:00:49.936 A:middle
about making code run fast.

00:00:50.296 --> 00:00:52.636 A:middle
We believe that you can
build amazing things

00:00:52.636 --> 00:00:54.136 A:middle
when your apps are
highly optimized.

00:00:54.406 --> 00:01:00.736 A:middle
And if you feel the same way,
then this talk is for you.



00:00:54.406 --> 00:01:00.736 A:middle
And if you feel the same way,
then this talk is for you.

00:01:01.916 --> 00:01:04.075 A:middle
Today I'll start by
telling you about some

00:01:04.075 --> 00:01:05.716 A:middle
of the new compiler
optimizations

00:01:05.836 --> 00:01:07.316 A:middle
that we have added
over the last year.

00:01:07.996 --> 00:01:11.756 A:middle
Later, Michael will describe
the underlying implementation

00:01:11.756 --> 00:01:13.506 A:middle
of Swift and give
you some advice

00:01:13.736 --> 00:01:15.436 A:middle
on writing high-performance
Swift code.

00:01:15.956 --> 00:01:18.446 A:middle
And finally, Joe
will demonstrate how

00:01:18.446 --> 00:01:20.556 A:middle
to use instruments to identify

00:01:20.936 --> 00:01:25.786 A:middle
and analyze performance
bottlenecks in your Swift code.

00:01:26.736 --> 00:01:32.106 A:middle
So Swift is a flexible and safe
programming language with lots

00:01:32.106 --> 00:01:36.786 A:middle
of great features, like closures
and protocols and generics and,

00:01:36.786 --> 00:01:38.526 A:middle
of course, automatic
reference counting.

00:01:38.986 --> 00:01:42.606 A:middle
Now, some of you may associate
these features with slowness

00:01:42.826 --> 00:01:45.236 A:middle
because the program
has to do more work

00:01:45.356 --> 00:01:46.896 A:middle
to implement these
high-level features.

00:01:47.616 --> 00:01:50.806 A:middle
But Swift is a very fast
programming language that's

00:01:50.856 --> 00:01:53.086 A:middle
compiled to highly
optimized native code.

00:01:54.096 --> 00:01:56.206 A:middle
So how did we make Swift fast?

00:01:57.226 --> 00:01:59.756 A:middle
Well, we made Swift fast



00:02:00.066 --> 00:02:04.016 A:middle
by implementing compiler
optimizations that target all

00:02:04.016 --> 00:02:05.396 A:middle
of these high-level features.

00:02:05.866 --> 00:02:09.265 A:middle
These compiler optimizations
make sure that the overhead

00:02:09.596 --> 00:02:12.496 A:middle
of the high-level
features is minimal.

00:02:14.476 --> 00:02:16.916 A:middle
Now, we have lots of
compiler optimizations,

00:02:16.916 --> 00:02:19.376 A:middle
and we don't have enough
time to go over all of them,

00:02:19.676 --> 00:02:22.056 A:middle
so I decided to bring
you one example

00:02:22.136 --> 00:02:23.556 A:middle
of one compiler optimization.

00:02:24.126 --> 00:02:26.986 A:middle
This optimization is called
bounds checks elimination.

00:02:29.636 --> 00:02:31.926 A:middle
On the screen, you can
see a very simple loop.

00:02:32.186 --> 00:02:34.076 A:middle
This loop encrypts the
content of the array

00:02:34.346 --> 00:02:37.646 A:middle
by X-raying all the elements in
the array with the number 13.

00:02:37.906 --> 00:02:39.056 A:middle
It's not a very good encryption.

00:02:39.846 --> 00:02:43.116 A:middle
The reading and writing
outside of the bounds

00:02:43.116 --> 00:02:45.046 A:middle
of the array is a serious bug

00:02:45.506 --> 00:02:47.386 A:middle
and can also have
security implications,

00:02:48.086 --> 00:02:52.456 A:middle
and Swift is protecting you
by adding a little bit of code

00:02:52.546 --> 00:02:54.596 A:middle
that checks that you don't
read or write outside

00:02:54.596 --> 00:02:55.426 A:middle
of the bounds of the array.

00:02:56.106 --> 00:03:00.056 A:middle
Now, the problem is that this
check slows your code down.



00:02:56.106 --> 00:03:00.056 A:middle
Now, the problem is that this
check slows your code down.

00:03:02.186 --> 00:03:05.366 A:middle
Another problem is that it
blocks other optimizations.

00:03:05.366 --> 00:03:07.976 A:middle
For example, we cannot
vectorize this code

00:03:08.396 --> 00:03:09.316 A:middle
with this check in place.

00:03:10.536 --> 00:03:13.186 A:middle
So we've implemented a
compiler optimization

00:03:13.616 --> 00:03:17.046 A:middle
for hoisting this check outside
of the loop, making the cost

00:03:17.046 --> 00:03:19.976 A:middle
of the check negligible,
because instead of checking

00:03:20.056 --> 00:03:21.476 A:middle
on each iteration of the loop

00:03:21.796 --> 00:03:24.046 A:middle
that we are hitting inside
the bounds of the array,

00:03:24.266 --> 00:03:26.676 A:middle
we are only checking once
when we enter the array.

00:03:27.186 --> 00:03:28.936 A:middle
So this is a very
powerful optimization

00:03:29.456 --> 00:03:32.966 A:middle
that makes numeric
code run faster.

00:03:33.076 --> 00:03:36.316 A:middle
Okay. So this was one
example of one optimization,

00:03:36.616 --> 00:03:38.626 A:middle
and we have lots
of optimizations.

00:03:39.316 --> 00:03:41.016 A:middle
And we know that these
optimizations work

00:03:41.206 --> 00:03:44.866 A:middle
and that they are very effective
because we are tracking hundreds

00:03:44.866 --> 00:03:47.586 A:middle
of programs and benchmarks,
and over the last year,

00:03:47.836 --> 00:03:50.926 A:middle
we noticed that these programs
became significantly faster.

00:03:51.386 --> 00:03:53.556 A:middle
Every time we added
a new optimization,

00:03:53.926 --> 00:03:55.536 A:middle
every time we made
an improvement

00:03:55.776 --> 00:03:57.186 A:middle
to existing optimizations,

00:03:57.456 --> 00:03:59.656 A:middle
we noticed that these
programs became faster.



00:04:00.786 --> 00:04:03.546 A:middle
Now, it's not going to be very
interesting for you to see all

00:04:03.546 --> 00:04:06.956 A:middle
of these programs, so I decided
to bring you five programs.

00:04:08.116 --> 00:04:09.096 A:middle
The programs that you see

00:04:09.096 --> 00:04:11.406 A:middle
on the screen behind me
right now are programs

00:04:11.406 --> 00:04:12.356 A:middle
from multiple domains.

00:04:13.286 --> 00:04:15.966 A:middle
One is an object-oriented
program.

00:04:16.055 --> 00:04:17.305 A:middle
Another one is numeric.

00:04:17.466 --> 00:04:19.146 A:middle
Another one is functional.

00:04:20.456 --> 00:04:22.786 A:middle
And I believe that these
programs represent the kind

00:04:22.786 --> 00:04:25.406 A:middle
of code that users
write today in Swift.

00:04:26.346 --> 00:04:27.996 A:middle
And as you can see,
over the last year,

00:04:28.566 --> 00:04:30.346 A:middle
these programs became
significantly faster,

00:04:30.346 --> 00:04:33.046 A:middle
between two to eight times
faster, which is great.

00:04:33.506 --> 00:04:36.306 A:middle
Now, these programs are
optimized in release mode.

00:04:37.226 --> 00:04:39.766 A:middle
But I know that you also
care about the performance

00:04:39.766 --> 00:04:42.826 A:middle
of unoptimized programs
because you are spending a lot

00:04:42.826 --> 00:04:45.646 A:middle
of time writing your code and
debugging it and running it

00:04:45.646 --> 00:04:46.816 A:middle
in simulator, so you care

00:04:46.816 --> 00:04:48.396 A:middle
about the performance
of unoptimized code.

00:04:49.486 --> 00:04:51.416 A:middle
So, these are the
same five programs,

00:04:51.986 --> 00:04:54.046 A:middle
this time in debug mode.

00:04:54.516 --> 00:04:55.316 A:middle
They are unoptimized.

00:04:55.996 --> 00:04:58.626 A:middle
So you are probably
asking yourself, wait,

00:04:58.716 --> 00:04:59.946 A:middle
how can improvements

00:04:59.946 --> 00:05:04.306 A:middle
to the optimizer improve the
performance of unoptimized code.



00:04:59.946 --> 00:05:04.306 A:middle
to the optimizer improve the
performance of unoptimized code.

00:05:04.626 --> 00:05:08.146 A:middle
Right? Well, we made
unoptimized code run faster

00:05:08.146 --> 00:05:09.046 A:middle
by doing two things.

00:05:09.406 --> 00:05:12.526 A:middle
First of all, we improved
the Swift runtime component.

00:05:12.806 --> 00:05:17.096 A:middle
The runtime is responsible
for allocating memory,

00:05:17.096 --> 00:05:19.426 A:middle
accessing metadata,
things like that.

00:05:19.506 --> 00:05:20.426 A:middle
So we optimized that.

00:05:20.946 --> 00:05:24.436 A:middle
And the second thing that we
did is that now we are able

00:05:24.436 --> 00:05:26.926 A:middle
to optimize the Swift
Standard Library better.

00:05:27.076 --> 00:05:28.406 A:middle
The Standard Library
is the component

00:05:28.406 --> 00:05:31.966 A:middle
that has the implementation of
array and dictionary and set.

00:05:32.286 --> 00:05:35.756 A:middle
So by optimizing the
Standard Library better,

00:05:36.056 --> 00:05:38.206 A:middle
we are able to accelerate
the performance

00:05:38.206 --> 00:05:41.016 A:middle
of unoptimized programs.

00:05:41.396 --> 00:05:43.656 A:middle
We know that over the
last year, the performance

00:05:43.656 --> 00:05:45.156 A:middle
of both optimized

00:05:45.476 --> 00:05:48.866 A:middle
and unoptimized programs
became significantly better.

00:05:49.436 --> 00:05:50.616 A:middle
But to get the full picture,

00:05:50.616 --> 00:05:53.986 A:middle
I want to show you a
comparison to Objective-C.

00:05:54.536 --> 00:05:58.706 A:middle
So on the screen you can see
two very well-known benchmarks.

00:05:59.116 --> 00:06:01.176 A:middle
It's Richards and
DeltaBlue, both written



00:05:59.116 --> 00:06:01.176 A:middle
It's Richards and
DeltaBlue, both written

00:06:01.176 --> 00:06:02.686 A:middle
in object-oriented style.

00:06:03.216 --> 00:06:04.266 A:middle
And on these benchmarks,

00:06:04.516 --> 00:06:06.796 A:middle
Swift is a lot faster
than Objective-C.

00:06:07.476 --> 00:06:09.646 A:middle
At this point in the
talk, I am not going

00:06:09.646 --> 00:06:12.226 A:middle
to tell you why Swift is
faster than Objective-C,

00:06:12.686 --> 00:06:14.856 A:middle
but I promise you that we
will get back to this slide

00:06:15.256 --> 00:06:18.466 A:middle
and we will talk about
why Swift is faster.

00:06:19.416 --> 00:06:22.556 A:middle
Okay. Now I am going to talk
about something different.

00:06:22.856 --> 00:06:25.816 A:middle
I want to talk about a new
compiler optimization mode

00:06:25.946 --> 00:06:28.116 A:middle
that's called "Whole
Module Optimization"

00:06:28.376 --> 00:06:30.696 A:middle
that can make your programs
run significantly faster.

00:06:31.526 --> 00:06:33.466 A:middle
But before I do that,
I would like to talk

00:06:33.466 --> 00:06:36.526 A:middle
about the way Xcode
compiles files.

00:06:37.496 --> 00:06:41.436 A:middle
So Xcode compiles your
files individually.

00:06:42.156 --> 00:06:45.236 A:middle
And this is a good idea because
it can compile many files

00:06:45.236 --> 00:06:47.656 A:middle
in parallel on multiple
cores in your machine.

00:06:48.156 --> 00:06:48.636 A:middle
That's good.

00:06:49.046 --> 00:06:52.856 A:middle
It can also recompile only
files that need to be updated.

00:06:53.366 --> 00:06:53.916 A:middle
So that's good.

00:06:54.536 --> 00:06:56.956 A:middle
But the problem is that
the optimizer is limited

00:06:56.956 --> 00:06:59.006 A:middle
to the scope of one file.

00:06:59.826 --> 00:07:05.156 A:middle
With Whole Module Optimization,
the compiler is able



00:06:59.826 --> 00:07:05.156 A:middle
With Whole Module Optimization,
the compiler is able

00:07:05.156 --> 00:07:09.016 A:middle
to optimize the entire module
at once, which is great

00:07:09.126 --> 00:07:10.786 A:middle
because it can analyze
everything

00:07:10.786 --> 00:07:12.936 A:middle
and make aggressive
optimizations.

00:07:13.566 --> 00:07:17.266 A:middle
Now, naturally, Whole Module
Optimization builds take longer.

00:07:19.106 --> 00:07:22.226 A:middle
But the generated binaries
usually run faster.

00:07:24.636 --> 00:07:27.236 A:middle
In Swift 2, we made
two major improvements

00:07:27.286 --> 00:07:28.506 A:middle
to Whole Module Optimizations.

00:07:28.586 --> 00:07:33.016 A:middle
So first, we added new
optimizations that rely

00:07:33.506 --> 00:07:35.086 A:middle
on Whole Module Optimization
mode.

00:07:36.016 --> 00:07:38.266 A:middle
So your programs are
likely to run faster.

00:07:38.976 --> 00:07:43.166 A:middle
And second, we were able
to parallelize some parts

00:07:43.166 --> 00:07:44.316 A:middle
of the compilation pipeline.

00:07:44.816 --> 00:07:48.546 A:middle
So compiling projects in Whole
Module Optimization mode should

00:07:48.576 --> 00:07:49.846 A:middle
take less time.

00:07:50.446 --> 00:07:55.206 A:middle
On the screen behind me,
you can see two programs

00:07:55.206 --> 00:07:57.926 A:middle
that became significantly faster
with Whole Module Optimization

00:07:58.046 --> 00:08:01.036 A:middle
because the compiler was able
to make better decisions,



00:07:58.046 --> 00:08:01.036 A:middle
because the compiler was able
to make better decisions,

00:08:01.076 --> 00:08:03.366 A:middle
it was able to analyze
the entire module

00:08:03.726 --> 00:08:05.726 A:middle
and make more aggressive
optimizations

00:08:06.106 --> 00:08:09.006 A:middle
with the information
that it had.

00:08:10.126 --> 00:08:12.316 A:middle
In Xcode 7, we've
made some changes

00:08:12.316 --> 00:08:13.706 A:middle
to the optimization level menu,

00:08:14.206 --> 00:08:16.896 A:middle
and now Whole Module
Optimization is one

00:08:16.896 --> 00:08:18.656 A:middle
of the options that
you can select.

00:08:19.226 --> 00:08:21.436 A:middle
And I encourage you to try
Whole Module Optimization

00:08:21.796 --> 00:08:22.456 A:middle
on your programs.

00:08:23.006 --> 00:08:25.896 A:middle
At this point, I would like
to invite Michael on stage

00:08:25.946 --> 00:08:28.666 A:middle
to tell you about the underlying
implementation of Swift

00:08:28.666 --> 00:08:30.196 A:middle
and give you some advice

00:08:30.196 --> 00:08:32.176 A:middle
on writing high-performance
Swift code.

00:08:32.655 --> 00:08:32.905 A:middle
Thank you.

00:08:33.515 --> 00:08:43.706 A:middle
[Applause]

00:08:44.206 --> 00:08:45.596 A:middle
&gt;&gt; MICHAEL GOTTESMAN:
Thanks, Nadav.

00:08:46.186 --> 00:08:47.846 A:middle
Today I would like
to speak to you

00:08:48.186 --> 00:08:51.466 A:middle
about three different aspects of
the Swift programming language

00:08:51.536 --> 00:08:53.146 A:middle
and their performance
characteristics.

00:08:53.736 --> 00:08:57.266 A:middle
For each I will give specific
techniques that you can use

00:08:57.416 --> 00:08:59.766 A:middle
to improve the performance
of your app today.



00:09:00.506 --> 00:09:04.126 A:middle
Let's begin by talking
about reference counting.

00:09:04.756 --> 00:09:07.956 A:middle
In general, the compiler
can eliminate most reference

00:09:07.956 --> 00:09:09.626 A:middle
counting overhead
without any help.

00:09:10.436 --> 00:09:13.686 A:middle
But sometimes you may still
find slowdowns in your code due

00:09:13.686 --> 00:09:14.996 A:middle
to reference counting overhead.

00:09:15.946 --> 00:09:19.586 A:middle
Today I'm going to present two
techniques that you can use

00:09:19.856 --> 00:09:22.096 A:middle
to reduce or even
eliminate this overhead.

00:09:23.516 --> 00:09:26.026 A:middle
Let's begin by looking at the
basics of reference counting

00:09:26.356 --> 00:09:28.166 A:middle
by looking at how
reference counting

00:09:28.166 --> 00:09:29.176 A:middle
and classes go together.

00:09:30.656 --> 00:09:32.866 A:middle
So here I have a block of code.

00:09:33.106 --> 00:09:36.266 A:middle
It consists of a class C,
a function foo that takes

00:09:36.266 --> 00:09:39.146 A:middle
in an optional C, and a couple
of variable definitions.

00:09:39.606 --> 00:09:41.926 A:middle
Let's walk through the code's
execution line by line.

00:09:43.656 --> 00:09:46.766 A:middle
First we begin by allocating
new instance of class C

00:09:46.766 --> 00:09:48.816 A:middle
and assign it to the variable X.

00:09:49.776 --> 00:09:52.546 A:middle
Notice how at the top of the
class instance, there is a box

00:09:52.546 --> 00:09:53.376 A:middle
with the number 1 in it.

00:09:53.546 --> 00:09:56.226 A:middle
This represents the reference
count of the class instance.

00:09:56.996 --> 00:09:59.446 A:middle
Of course, it's 1 because
there's only one reference

00:09:59.486 --> 00:10:01.426 A:middle
to the class instance
currently, namely x.



00:09:59.486 --> 00:10:01.426 A:middle
to the class instance
currently, namely x.

00:10:02.896 --> 00:10:05.856 A:middle
Then we assign x
to the variable y.

00:10:06.016 --> 00:10:08.036 A:middle
This creates a new reference
to the class instance,

00:10:08.326 --> 00:10:10.406 A:middle
causing us to increment
the reference count

00:10:10.406 --> 00:10:13.606 A:middle
of the class instance, giving
us a reference count of 2.

00:10:14.856 --> 00:10:16.636 A:middle
Then we pass off y to foo,

00:10:16.636 --> 00:10:18.776 A:middle
but we don't actually
pass off y itself.

00:10:18.856 --> 00:10:24.686 A:middle
Instead, we create a temporary
C, and then we assign y to C.

00:10:25.176 --> 00:10:29.266 A:middle
This then acts as a third
reference to the class instance,

00:10:29.526 --> 00:10:31.586 A:middle
which then causes us to
increment the reference count

00:10:31.586 --> 00:10:32.816 A:middle
of the class instance once more.

00:10:33.916 --> 00:10:37.326 A:middle
Then when foo exits, C is
destroyed, which then causes us

00:10:37.326 --> 00:10:39.476 A:middle
to decrement the reference
count of the class instance,

00:10:39.716 --> 00:10:42.106 A:middle
bringing us to a
reference count of 2.

00:10:42.356 --> 00:10:45.436 A:middle
Then finally, we assign
nil to y and nil to x,

00:10:45.856 --> 00:10:48.166 A:middle
bringing the reference count
of our class instance to 0,

00:10:48.166 --> 00:10:49.896 A:middle
and then it's deallocated.

00:10:51.656 --> 00:10:55.266 A:middle
Notice how every time
we made an assignment,

00:10:55.556 --> 00:10:58.066 A:middle
we had to perform a
reference counting operation

00:10:58.226 --> 00:11:00.346 A:middle
to maintain the reference
count of the class instance.



00:10:58.226 --> 00:11:00.346 A:middle
to maintain the reference
count of the class instance.

00:11:01.246 --> 00:11:02.836 A:middle
This is important
since we always have

00:11:02.836 --> 00:11:05.766 A:middle
to maintain memory safety.

00:11:05.876 --> 00:11:09.296 A:middle
Now, for those of you who are
familiar with Objective-C,

00:11:09.296 --> 00:11:11.856 A:middle
of course, nothing new is
happening here with, of course,

00:11:12.296 --> 00:11:17.016 A:middle
increment and decrement
being respectfully retained

00:11:17.676 --> 00:11:18.316 A:middle
and released.

00:11:19.246 --> 00:11:21.216 A:middle
But now I'd like to talk to you

00:11:21.216 --> 00:11:23.496 A:middle
about something that's
perhaps a bit more exotic,

00:11:23.496 --> 00:11:24.436 A:middle
more unfamiliar.

00:11:24.856 --> 00:11:28.086 A:middle
Namely, how structs interact
with reference counting.

00:11:29.356 --> 00:11:33.426 A:middle
I'll begin -- let's begin this
discussion by looking at a class

00:11:33.546 --> 00:11:35.176 A:middle
that doesn't contain
any references.

00:11:36.686 --> 00:11:37.836 A:middle
Here I have a class, Point.

00:11:37.836 --> 00:11:40.016 A:middle
Of course, it doesn't
contain any references,

00:11:40.446 --> 00:11:41.936 A:middle
but it does have two
properties in it,

00:11:41.936 --> 00:11:43.776 A:middle
x and y, that are both floats.

00:11:44.716 --> 00:11:47.036 A:middle
If I store one of these
points in an array,

00:11:47.466 --> 00:11:48.786 A:middle
because it's a class, of course,

00:11:48.786 --> 00:11:50.716 A:middle
I don't store it
directly in the array.

00:11:51.006 --> 00:11:53.706 A:middle
Instead, I store reference
to the points in the array.

00:11:54.636 --> 00:11:56.906 A:middle
So when I iterate
over the array,

00:11:56.906 --> 00:12:01.346 A:middle
when I initialize
the loop variable p,



00:11:56.906 --> 00:12:01.346 A:middle
when I initialize
the loop variable p,

00:12:01.346 --> 00:12:04.876 A:middle
I am actually creating a new
reference to the class instance,

00:12:05.296 --> 00:12:07.926 A:middle
meaning that I have to perform
a reference count increment.

00:12:08.946 --> 00:12:11.786 A:middle
Then, when p is destroyed at
the end of the loop iteration,

00:12:11.836 --> 00:12:14.166 A:middle
I then have to decrement
that reference count.

00:12:15.296 --> 00:12:17.806 A:middle
In Objective-C, one
would oftentimes have

00:12:17.956 --> 00:12:20.536 A:middle
to make simple data
structures, like Point,

00:12:20.536 --> 00:12:22.716 A:middle
a class so you could
use data structures

00:12:22.716 --> 00:12:24.226 A:middle
from Foundation like NSRA.

00:12:24.986 --> 00:12:27.606 A:middle
Then whenever you manipulated
the simple data structure,

00:12:27.786 --> 00:12:29.716 A:middle
you would have the
overhead of having a class.

00:12:30.676 --> 00:12:32.936 A:middle
In Swift, we can use structs --

00:12:33.176 --> 00:12:36.056 A:middle
in Swift, we can work around
this issue by using a struct

00:12:36.056 --> 00:12:37.396 A:middle
in this case instead of a class.

00:12:38.516 --> 00:12:41.056 A:middle
So let's make Point a struct.

00:12:41.566 --> 00:12:44.926 A:middle
Immediately, we can store each
Point in the array directly,

00:12:44.926 --> 00:12:47.206 A:middle
since Swift arrays can
store structs directly.

00:12:47.206 --> 00:12:51.156 A:middle
But more importantly, since
a struct does not inherently

00:12:51.156 --> 00:12:54.176 A:middle
require reference counting
and both properties

00:12:54.496 --> 00:12:57.136 A:middle
of the struct also don't
require reference counting,

00:12:57.366 --> 00:13:00.636 A:middle
we can immediately eliminate all
the reference counting overhead



00:12:57.366 --> 00:13:00.636 A:middle
we can immediately eliminate all
the reference counting overhead

00:13:00.636 --> 00:13:02.846 A:middle
from the loop.

00:13:03.106 --> 00:13:06.416 A:middle
Let's now consider a slightly
more elaborate example of this

00:13:06.416 --> 00:13:12.806 A:middle
by considering a struct with
a reference inside of it.

00:13:13.086 --> 00:13:15.956 A:middle
While a struct itself does not
inherently require reference

00:13:15.956 --> 00:13:17.556 A:middle
counting modifications
on assignment,

00:13:17.556 --> 00:13:21.026 A:middle
like I mentioned before, it
does require such modifications

00:13:21.076 --> 00:13:22.836 A:middle
if the struct contains
a reference.

00:13:23.836 --> 00:13:26.866 A:middle
This is because assigning
a struct is equivalent

00:13:27.016 --> 00:13:28.026 A:middle
to assigning each one

00:13:28.026 --> 00:13:30.166 A:middle
of its properties
independently of each other.

00:13:31.266 --> 00:13:33.606 A:middle
So consider that the struct
Point that we saw previously,

00:13:35.096 --> 00:13:36.426 A:middle
it is copied efficiently,

00:13:36.426 --> 00:13:38.736 A:middle
there are no reference counting
needed when we assign it.

00:13:39.166 --> 00:13:42.766 A:middle
But let's say that one
day I'm working on my app

00:13:42.766 --> 00:13:44.776 A:middle
and I decide that, well, I
would like to make each one

00:13:44.776 --> 00:13:47.476 A:middle
of my Points to be
drawn a different color.

00:13:47.576 --> 00:13:51.586 A:middle
So I add a UIColor
property to my struct.

00:13:52.086 --> 00:13:53.486 A:middle
Of course, UIColor
being a class,

00:13:53.486 --> 00:13:56.366 A:middle
this is actually adding
a reference to my struct.

00:13:56.986 --> 00:14:00.906 A:middle
Now, this means that every
time I assign this struct,



00:13:56.986 --> 00:14:00.906 A:middle
Now, this means that every
time I assign this struct,

00:14:01.326 --> 00:14:03.926 A:middle
it's equivalent to assigning
this UIColor independently

00:14:03.926 --> 00:14:05.896 A:middle
of the struct, which
means that I have

00:14:05.896 --> 00:14:08.896 A:middle
to perform a reference
counting modification.

00:14:10.326 --> 00:14:14.626 A:middle
Now, while having a struct with
one reference count in it is not

00:14:14.626 --> 00:14:17.756 A:middle
that expensive, I mean, we
work with classes all the time,

00:14:17.756 --> 00:14:19.356 A:middle
and classes have
the same property.

00:14:19.896 --> 00:14:23.746 A:middle
I would now like to present
to you a more extreme example,

00:14:24.296 --> 00:14:27.496 A:middle
namely, a struct with many
reference counted fields.

00:14:29.066 --> 00:14:32.436 A:middle
Here I have a struct user, and
I am using it to model users

00:14:32.436 --> 00:14:33.356 A:middle
in an app I am writing.

00:14:33.706 --> 00:14:37.056 A:middle
And each user instance has some
data associated with it, namely,

00:14:37.136 --> 00:14:40.916 A:middle
three strings -- one for
the first name of the user,

00:14:41.366 --> 00:14:43.536 A:middle
one for the last
name of the user,

00:14:43.576 --> 00:14:45.766 A:middle
and one for the user's address.

00:14:46.876 --> 00:14:49.706 A:middle
I also have a field for
an array and a dictionary

00:14:49.706 --> 00:14:52.766 A:middle
that stores app-specific
data about the user.

00:14:54.376 --> 00:14:57.706 A:middle
Even though all of these
properties are value types,

00:14:58.606 --> 00:15:02.006 A:middle
internally, they contain
a class which is used



00:14:58.606 --> 00:15:02.006 A:middle
internally, they contain
a class which is used

00:15:02.416 --> 00:15:05.756 A:middle
to manage the lifetime
of their internal data.

00:15:06.966 --> 00:15:10.086 A:middle
So this means that every time
I assign one of these structs,

00:15:11.396 --> 00:15:14.366 A:middle
every time I pass it off to
a function, I actually have

00:15:14.366 --> 00:15:17.796 A:middle
to perform five reference
counting modifications.

00:15:19.226 --> 00:15:22.056 A:middle
Well, we can work around this
by using a wrapper class.

00:15:23.416 --> 00:15:26.206 A:middle
Here again, I have my user
struct, but this time,

00:15:26.206 --> 00:15:28.606 A:middle
instead of standing on
its own, it's contained

00:15:28.606 --> 00:15:29.476 A:middle
within a wrapper class.

00:15:30.126 --> 00:15:32.816 A:middle
I can still manipulate the
struct using the class reference

00:15:32.816 --> 00:15:36.296 A:middle
and, more importantly, if I pass
off this reference to a function

00:15:36.506 --> 00:15:38.296 A:middle
or I declare -- or I sign --

00:15:38.296 --> 00:15:39.766 A:middle
initialize a variable
with the reference,

00:15:39.826 --> 00:15:43.156 A:middle
I am only performing one
reference count increment.

00:15:44.466 --> 00:15:46.836 A:middle
Now, it's important to note

00:15:47.476 --> 00:15:49.686 A:middle
that there's been a
change in semantics here.

00:15:50.366 --> 00:15:54.386 A:middle
We've changed from using
something with value semantics

00:15:54.866 --> 00:15:56.996 A:middle
to something with
reference semantics.

00:15:58.356 --> 00:16:02.346 A:middle
This may cause unexpected
data sharing that may lead



00:15:58.356 --> 00:16:02.346 A:middle
This may cause unexpected
data sharing that may lead

00:16:02.346 --> 00:16:04.676 A:middle
to weird results or things
that you may not expect.

00:16:06.086 --> 00:16:08.506 A:middle
But turns out there is a way

00:16:08.506 --> 00:16:12.566 A:middle
that you can have value
semantics and benefit

00:16:12.566 --> 00:16:13.586 A:middle
from this optimization.

00:16:14.616 --> 00:16:15.976 A:middle
If you'd like to
learn more about this,

00:16:16.126 --> 00:16:20.256 A:middle
please go to the Building Better
Apps with Value Types talk

00:16:20.256 --> 00:16:22.366 A:middle
in Swift tomorrow in Mission

00:16:22.366 --> 00:16:24.686 A:middle
at 2:30 p.m. It's going
to be a great talk.

00:16:24.686 --> 00:16:29.686 A:middle
I really suggest that you go.

00:16:29.686 --> 00:16:32.106 A:middle
Now that we've talked
about reference counting,

00:16:32.876 --> 00:16:36.426 A:middle
I'd like to continue by talking
a little bit about generics.

00:16:39.736 --> 00:16:41.796 A:middle
Here I have a generic
function min.

00:16:41.956 --> 00:16:44.276 A:middle
It's generic over
type T that conforms

00:16:44.276 --> 00:16:47.276 A:middle
to the comparable protocol from
the Swift Standard Library.

00:16:47.766 --> 00:16:49.476 A:middle
From a source code perspective,

00:16:49.756 --> 00:16:51.116 A:middle
this doesn't really
look that big.

00:16:51.116 --> 00:16:52.396 A:middle
I mean, it's just three lines.

00:16:53.136 --> 00:16:55.426 A:middle
But in reality, a
lot more is going

00:16:55.426 --> 00:16:57.366 A:middle
on behind the scenes
than one might think.

00:16:57.916 --> 00:17:00.896 A:middle
For instance, the code
that's actually emitted --



00:16:57.916 --> 00:17:00.896 A:middle
For instance, the code
that's actually emitted --

00:17:00.896 --> 00:17:02.686 A:middle
here, again I am
using a pseudo-Swift

00:17:02.686 --> 00:17:04.195 A:middle
to represent the code
the compiler emits --

00:17:04.195 --> 00:17:07.175 A:middle
the code the compiler emits
is not these three lines.

00:17:07.266 --> 00:17:09.965 A:middle
Instead, it's this.

00:17:10.695 --> 00:17:13.656 A:middle
First notice that the
compiler is using indirection

00:17:13.656 --> 00:17:15.056 A:middle
to compare both x and y.

00:17:15.506 --> 00:17:18.136 A:middle
This is because we could
be passing in two integers

00:17:18.136 --> 00:17:22.116 A:middle
to the min function, or we
could be passing in two floats

00:17:22.116 --> 00:17:24.685 A:middle
or two strings, or we could be
passing in any comparable type.

00:17:24.685 --> 00:17:28.016 A:middle
So the compiler must be
correct in all cases and be able

00:17:28.016 --> 00:17:29.796 A:middle
to handle any of them.

00:17:30.116 --> 00:17:32.796 A:middle
Additionally, because
the compiler can't know

00:17:32.976 --> 00:17:35.696 A:middle
if T requires reference
counting modifications or not,

00:17:35.926 --> 00:17:37.786 A:middle
it must insert additional
indirection

00:17:38.076 --> 00:17:41.586 A:middle
so the min T function
can handle both types T

00:17:41.586 --> 00:17:45.936 A:middle
that require reference counting
and those types T that do not.

00:17:46.116 --> 00:17:47.876 A:middle
In the case of an
integer, for instance,

00:17:48.166 --> 00:17:51.116 A:middle
these are just no-up calls
into the Swift runtime.

00:17:52.716 --> 00:17:55.896 A:middle
In both of these cases, the
compiler is being conservative

00:17:56.126 --> 00:17:59.986 A:middle
since it must be able to
handle any type T in this case.



00:18:01.536 --> 00:18:03.796 A:middle
Luckily, there is a
compiler optimization

00:18:03.796 --> 00:18:06.036 A:middle
that can help us here, that
can remove this overhead.

00:18:06.736 --> 00:18:09.796 A:middle
This compiler optimization is
called generic specialization.

00:18:10.906 --> 00:18:13.816 A:middle
Here I have a function
foo, it passes two integers

00:18:13.816 --> 00:18:15.216 A:middle
to the generic min-T function.

00:18:15.986 --> 00:18:18.746 A:middle
When the compiler performs
generic specialization,

00:18:19.056 --> 00:18:21.696 A:middle
first it looks at the call
to min and foo and sees, oh,

00:18:22.326 --> 00:18:23.726 A:middle
there are two integers
being passed

00:18:23.926 --> 00:18:25.396 A:middle
to the generic min-T
function here.

00:18:26.276 --> 00:18:30.666 A:middle
Then since the compiler
can see the definition

00:18:30.666 --> 00:18:34.386 A:middle
of the generic min-T
function, it can clone min-T

00:18:34.386 --> 00:18:36.286 A:middle
and specialize this
clone function

00:18:36.286 --> 00:18:41.416 A:middle
by replacing the generic type T
with the specialized type Int.

00:18:42.596 --> 00:18:45.156 A:middle
Then the specialized
function is optimized for Int,

00:18:45.676 --> 00:18:49.136 A:middle
and all the overhead associated
with this function is removed,

00:18:49.136 --> 00:18:50.276 A:middle
so all the reference count --

00:18:50.276 --> 00:18:52.546 A:middle
the unnecessary reference
counting calls are removed,

00:18:52.546 --> 00:18:54.866 A:middle
and we can compare the
two integers directly.

00:18:56.356 --> 00:18:58.556 A:middle
Finally, the compiler
replaces the call

00:18:58.556 --> 00:19:01.126 A:middle
to the generic min-T
function with a call



00:18:58.556 --> 00:19:01.126 A:middle
to the generic min-T
function with a call

00:19:01.126 --> 00:19:04.066 A:middle
to the specialized
min Int function,

00:19:04.306 --> 00:19:06.046 A:middle
enabling further optimizations.

00:19:07.756 --> 00:19:11.756 A:middle
While generic specialization is
a very powerful optimization,

00:19:12.466 --> 00:19:15.986 A:middle
it does have one
limitation; namely, that --

00:19:15.986 --> 00:19:18.386 A:middle
namely, the visibility of
the generic definition.

00:19:18.596 --> 00:19:20.616 A:middle
For instance, this case,
the generic definition

00:19:20.616 --> 00:19:21.626 A:middle
of the min-T function.

00:19:22.956 --> 00:19:24.426 A:middle
Here we have a function compute

00:19:24.956 --> 00:19:27.176 A:middle
which calls a generic min-T
function with two integers.

00:19:27.906 --> 00:19:31.776 A:middle
In this case, can we perform
generic specialization?

00:19:32.566 --> 00:19:34.476 A:middle
Well, even though
the compiler can see

00:19:34.476 --> 00:19:36.096 A:middle
that two integers
are being passed

00:19:36.096 --> 00:19:37.516 A:middle
to the generic min-T function,

00:19:38.336 --> 00:19:40.426 A:middle
because we are compiling
file 1.Swift

00:19:41.046 --> 00:19:44.756 A:middle
and file 2.Swift separately,
the definition of functions

00:19:44.756 --> 00:19:47.506 A:middle
from file 2 are not
visible to the compiler

00:19:47.676 --> 00:19:49.946 A:middle
when the compiler
is compiling file 1.

00:19:50.116 --> 00:19:54.186 A:middle
So in this case, the compiler
cannot see the definition

00:19:54.366 --> 00:19:57.536 A:middle
of the generic min-T function
when it's compiling file 1,

00:19:57.536 --> 00:20:01.206 A:middle
and so we must call the
generic min-T function.



00:19:57.536 --> 00:20:01.206 A:middle
and so we must call the
generic min-T function.

00:20:02.576 --> 00:20:06.466 A:middle
But what if we have Whole
Module Optimization enabled?

00:20:07.856 --> 00:20:10.876 A:middle
Well, if we have Whole
Module Optimization enabled,

00:20:11.216 --> 00:20:15.536 A:middle
both file 1.Swift and file
2.Swift are compiled together.

00:20:16.046 --> 00:20:17.976 A:middle
This means that definitions
from file 1

00:20:17.976 --> 00:20:19.976 A:middle
and file 2 are both visible

00:20:19.976 --> 00:20:22.656 A:middle
when you are compiling
file 1 or file 2 together.

00:20:22.656 --> 00:20:26.656 A:middle
So basically, this means that
the generic min-T function,

00:20:26.656 --> 00:20:28.046 A:middle
even though it's in file 2,

00:20:29.046 --> 00:20:32.606 A:middle
can be seen when we
are compiling file 1.

00:20:33.726 --> 00:20:36.706 A:middle
Thus, we are able to specialize
the generic min-T function

00:20:36.736 --> 00:20:41.246 A:middle
into min int and replace the
call to min-T with min Int.

00:20:42.396 --> 00:20:44.716 A:middle
This is but one case
where the power

00:20:44.716 --> 00:20:46.466 A:middle
of whole module optimization
is apparent.

00:20:47.166 --> 00:20:50.326 A:middle
The only reason the compiler can
perform generic specification

00:20:50.326 --> 00:20:54.186 A:middle
in this case is because of the
extra information provided to it

00:20:54.266 --> 00:20:56.866 A:middle
by having Whole Module
Optimization being enabled.



00:21:00.876 --> 00:21:05.466 A:middle
Now that I have spoken about
generics, I'd like to conclude

00:21:05.896 --> 00:21:08.656 A:middle
by talking about
dynamic dispatch.

00:21:11.236 --> 00:21:14.166 A:middle
Here I have a class
hierarchy for the class Pet.

00:21:15.196 --> 00:21:19.716 A:middle
Notice that Pet has a method
noise, a property name,

00:21:20.126 --> 00:21:22.656 A:middle
and a method noiseimpl,
which is used

00:21:22.656 --> 00:21:23.816 A:middle
to implement the method nose.

00:21:24.686 --> 00:21:27.026 A:middle
Also notice it has a subclass

00:21:27.026 --> 00:21:29.596 A:middle
of Pet called Dog
that overrides noise.

00:21:30.186 --> 00:21:32.526 A:middle
Now consider the
function make noise.

00:21:33.136 --> 00:21:34.526 A:middle
It's a very simple function,

00:21:34.656 --> 00:21:38.476 A:middle
it takes an argument p that's
an instance of class Pet.

00:21:38.886 --> 00:21:42.016 A:middle
Even though this block of code
only involves a small amount

00:21:42.016 --> 00:21:45.806 A:middle
of source again, a lot more is
occurring here behind the scenes

00:21:45.806 --> 00:21:46.566 A:middle
than one might think.

00:21:46.866 --> 00:21:50.056 A:middle
For instance, the following
pseudo-Swift code is not what is

00:21:50.056 --> 00:21:51.476 A:middle
actually emitted
by the compiler.

00:21:51.846 --> 00:21:53.796 A:middle
Name and noise are
not called directly.

00:21:53.876 --> 00:21:56.466 A:middle
Instead, the compiler
emits this code.

00:21:57.176 --> 00:21:58.956 A:middle
Notice the indirection
here that's used

00:21:58.956 --> 00:22:02.266 A:middle
to call names getter
or the method noise.



00:21:58.956 --> 00:22:02.266 A:middle
to call names getter
or the method noise.

00:22:02.436 --> 00:22:04.516 A:middle
The compiler must
insert this indirection

00:22:04.826 --> 00:22:08.076 A:middle
because it cannot know given the
current class hierarchy whether

00:22:08.076 --> 00:22:11.846 A:middle
or not the property name or
the method noise are meant

00:22:11.846 --> 00:22:13.476 A:middle
to be overridden by subclasses.

00:22:14.606 --> 00:22:17.316 A:middle
The compiler in this
case can only emit --

00:22:17.876 --> 00:22:21.356 A:middle
can only emit direct
calls if it can prove

00:22:21.856 --> 00:22:24.536 A:middle
that there are no
possible overrides

00:22:24.756 --> 00:22:27.546 A:middle
by any subclasses
of name or noise.

00:22:28.766 --> 00:22:32.056 A:middle
In the case of noise, this
is exactly what we want.

00:22:32.456 --> 00:22:34.446 A:middle
We want noise to be
able to be overridden

00:22:34.446 --> 00:22:35.746 A:middle
by subclasses in this API.

00:22:36.396 --> 00:22:38.296 A:middle
We want to make it so
that if I have an instance

00:22:38.296 --> 00:22:42.636 A:middle
of Pet that's really a dog, the
dog barks when I call noise.

00:22:42.636 --> 00:22:45.916 A:middle
And if I have an instance of
Pet that's actually a class,

00:22:46.246 --> 00:22:47.986 A:middle
that when I call
noise, we have a meow.

00:22:48.246 --> 00:22:49.266 A:middle
That makes perfect sense.

00:22:50.626 --> 00:22:54.626 A:middle
But in the case of name,
this is actually undesirable.

00:22:55.326 --> 00:22:56.586 A:middle
This is because in this API,

00:22:57.226 --> 00:23:01.006 A:middle
name is not -- is
never overridden.



00:22:57.226 --> 00:23:01.006 A:middle
name is not -- is
never overridden.

00:23:01.006 --> 00:23:02.696 A:middle
It's not necessary
to override name.

00:23:03.226 --> 00:23:04.106 A:middle
We can model this

00:23:04.606 --> 00:23:06.766 A:middle
by constraining this
API's class hierarchy.

00:23:08.186 --> 00:23:10.086 A:middle
There are two Swift language
features that I am going

00:23:10.086 --> 00:23:11.686 A:middle
to show you today
that you can use

00:23:11.716 --> 00:23:13.616 A:middle
to constrain your
API's class hierarchy.

00:23:14.066 --> 00:23:15.706 A:middle
The first are constraints
on inheritance,

00:23:16.176 --> 00:23:19.536 A:middle
and the second are constrains
on access via access control.

00:23:19.616 --> 00:23:23.586 A:middle
Let's begin by talking about
inheritance constraints,

00:23:23.646 --> 00:23:25.136 A:middle
namely, the final keyword.

00:23:25.646 --> 00:23:29.496 A:middle
When an API contains
a declaration

00:23:29.496 --> 00:23:32.556 A:middle
with the final keyword attached,
the API is communicating

00:23:32.556 --> 00:23:35.746 A:middle
that this declaration will never
be overridden by a subclass.

00:23:36.846 --> 00:23:38.476 A:middle
Consider again the
make noise example.

00:23:38.986 --> 00:23:42.006 A:middle
By default, the compiler
must use indirection

00:23:42.446 --> 00:23:44.196 A:middle
to call the getter for name.

00:23:44.576 --> 00:23:49.096 A:middle
This is because without more
information, it can't know

00:23:49.326 --> 00:23:51.226 A:middle
if name is overridden
by a subclass.

00:23:51.626 --> 00:23:56.096 A:middle
But we know that in this API,
name is never overridden,

00:23:56.096 --> 00:24:00.236 A:middle
and we know that in this API,
it's not intended for name



00:23:56.096 --> 00:24:00.236 A:middle
and we know that in this API,
it's not intended for name

00:24:00.236 --> 00:24:02.056 A:middle
to be able to be overridden.

00:24:02.226 --> 00:24:04.956 A:middle
So we can enforce this
and communicate this

00:24:05.026 --> 00:24:07.516 A:middle
by attaching the
final keyword to name.

00:24:08.956 --> 00:24:12.586 A:middle
Then the compiler can look
at name and realize, oh,

00:24:12.586 --> 00:24:14.256 A:middle
this will never be
overridden by a subclass,

00:24:14.256 --> 00:24:17.696 A:middle
and the dynamic dispatch, the
indirection, can be eliminated.

00:24:17.696 --> 00:24:22.866 A:middle
Now that we've talked about
final inheritance constraints,

00:24:22.936 --> 00:24:25.086 A:middle
I'd like to talk a little
bit about access control.

00:24:26.296 --> 00:24:30.776 A:middle
Turns out in this API, pet and
dog are both in separate files,

00:24:31.086 --> 00:24:35.056 A:middle
pet.Swift and dog.Swift, but are
in the same module, module A.

00:24:35.526 --> 00:24:39.046 A:middle
Additionally, there is another
subclass of pet called Cat

00:24:39.376 --> 00:24:42.446 A:middle
in a different module but
in the file cat.Swift.

00:24:42.596 --> 00:24:44.036 A:middle
The question I'd like to ask is,

00:24:44.116 --> 00:24:47.476 A:middle
can the compiler emit a
direct call to noiseimpl?

00:24:49.036 --> 00:24:50.466 A:middle
By default, it cannot.

00:24:51.146 --> 00:24:53.536 A:middle
This is because by default,
the compiler must assume

00:24:53.536 --> 00:24:56.986 A:middle
that this API intended for
noiseimpl to be overridden

00:24:56.986 --> 00:24:58.896 A:middle
in subclasses like Cat and Dog.

00:24:59.916 --> 00:25:02.516 A:middle
But we know that
this is not true.



00:24:59.916 --> 00:25:02.516 A:middle
But we know that
this is not true.

00:25:02.806 --> 00:25:06.936 A:middle
We know that noiseimpl is a
private implementation detail

00:25:07.376 --> 00:25:11.026 A:middle
of pet.Swift and that it
shouldn't be visible outside

00:25:11.026 --> 00:25:11.746 A:middle
of pet.swift.

00:25:12.616 --> 00:25:16.036 A:middle
We can enforce this by
attaching the private keyword

00:25:16.266 --> 00:25:16.956 A:middle
to noiseimpl.

00:25:18.136 --> 00:25:20.186 A:middle
Once we attach the private
keyword to noiseimpl,

00:25:20.506 --> 00:25:23.566 A:middle
noiseimpl is no longer
visible outside of pet.Swift.

00:25:24.436 --> 00:25:26.756 A:middle
This means that the
compiler can immediately know

00:25:27.016 --> 00:25:30.486 A:middle
that there cannot be any
overrides of noiseimpl in cat

00:25:30.486 --> 00:25:33.016 A:middle
or dog because, well,
they are not in pet.Swift,

00:25:33.016 --> 00:25:36.066 A:middle
and since there is only
one class in pet.Swift

00:25:36.566 --> 00:25:39.256 A:middle
that implements noiseimpl,
namely Pet,

00:25:39.416 --> 00:25:43.186 A:middle
the compiler can emit a direct
call to noiseimpl in this case.

00:25:44.546 --> 00:25:47.376 A:middle
Now that we've spoken about
private, I would like to talk

00:25:47.376 --> 00:25:50.156 A:middle
about the interaction between
Whole Module Optimization

00:25:50.156 --> 00:25:50.976 A:middle
and access control.

00:25:51.516 --> 00:25:54.246 A:middle
We have been talking a lot

00:25:54.246 --> 00:25:56.966 A:middle
about the class Pet,
but what about Dog?

00:25:58.036 --> 00:26:00.906 A:middle
Remember that Dog
is a subclass of Pet



00:25:58.036 --> 00:26:00.906 A:middle
Remember that Dog
is a subclass of Pet

00:26:00.906 --> 00:26:05.086 A:middle
that has internal access
instead of public access.

00:26:05.956 --> 00:26:08.356 A:middle
If we call noise on an
instance of class Dog,

00:26:08.786 --> 00:26:12.096 A:middle
without more information, the
compiler must insert indirection

00:26:12.626 --> 00:26:15.176 A:middle
because it cannot know if
there is a subclass of Dog

00:26:15.176 --> 00:26:16.826 A:middle
in a different file of module A.

00:26:17.896 --> 00:26:20.306 A:middle
But when we have Whole
Module Optimization enabled,

00:26:21.006 --> 00:26:23.456 A:middle
the compiler has
module-wide visibility.

00:26:23.976 --> 00:26:26.436 A:middle
It can see all the files
in the module together.

00:26:27.016 --> 00:26:29.946 A:middle
And so the compiler is
able to see, well, no,

00:26:29.946 --> 00:26:31.426 A:middle
there are no subclasses of dog,

00:26:31.846 --> 00:26:35.036 A:middle
so the compiler can
call noise directly

00:26:35.036 --> 00:26:36.806 A:middle
on instances of class Dog.

00:26:37.086 --> 00:26:40.146 A:middle
The key thing to notice here
is that all I needed to do was

00:26:40.146 --> 00:26:42.026 A:middle
to turn on Whole
Module Optimization.

00:26:42.546 --> 00:26:44.926 A:middle
I didn't need to
change my code at all.

00:26:45.706 --> 00:26:47.846 A:middle
By giving the compiler
more information,

00:26:48.186 --> 00:26:50.886 A:middle
by allowing the compiler to
understand my class hierarchy,

00:26:51.186 --> 00:26:54.206 A:middle
with more information I was
able to get this optimization

00:26:54.426 --> 00:26:59.356 A:middle
for free without
any work on my part.

00:26:59.526 --> 00:27:01.496 A:middle
Now I'd like to bring
back that graph



00:26:59.526 --> 00:27:01.496 A:middle
Now I'd like to bring
back that graph

00:27:01.496 --> 00:27:02.676 A:middle
that Nadav introduced earlier.

00:27:03.506 --> 00:27:10.306 A:middle
Why Is Swift so much
faster than Objective-C

00:27:11.286 --> 00:27:14.206 A:middle
on these object-oriented
benchmarks?

00:27:16.596 --> 00:27:20.016 A:middle
The reason why is
that in Objective-C,

00:27:20.856 --> 00:27:23.856 A:middle
the compiler cannot
eliminate the dynamic dispatch

00:27:23.856 --> 00:27:24.886 A:middle
through Ob-C message send.

00:27:25.126 --> 00:27:26.316 A:middle
It can't inline through it.

00:27:26.316 --> 00:27:27.706 A:middle
It can't perform any analysis.

00:27:27.826 --> 00:27:30.216 A:middle
The compiler must assume
that there could be anything

00:27:30.336 --> 00:27:32.046 A:middle
on the other side of
an Ob-C message send.

00:27:32.886 --> 00:27:35.906 A:middle
But in Swift, the compiler
has more information.

00:27:36.236 --> 00:27:39.466 A:middle
It's able to see all the certain
things on the other side.

00:27:39.466 --> 00:27:42.146 A:middle
It's able to eliminate this
dynamic dispatch in many cases.

00:27:43.246 --> 00:27:44.996 A:middle
And in those cases
where it does,

00:27:45.396 --> 00:27:47.476 A:middle
a lot more performance results,

00:27:47.736 --> 00:27:51.426 A:middle
resulting in significantly
faster code.

00:27:51.646 --> 00:27:55.406 A:middle
So please, use the final
keyword in access control

00:27:55.406 --> 00:27:57.036 A:middle
to communicate your
API's intent.

00:27:57.686 --> 00:28:00.426 A:middle
This will help the compiler to
understand your class hierarchy,



00:27:57.686 --> 00:28:00.426 A:middle
This will help the compiler to
understand your class hierarchy,

00:28:01.306 --> 00:28:03.806 A:middle
which will enable
additional optimizations.

00:28:04.016 --> 00:28:07.906 A:middle
However, keep in mind that
existing clients may need

00:28:07.906 --> 00:28:10.006 A:middle
to be updated in
response to such changes.

00:28:10.576 --> 00:28:12.186 A:middle
And try out Whole
Module Optimization

00:28:12.186 --> 00:28:12.986 A:middle
in your release builds.

00:28:12.986 --> 00:28:16.366 A:middle
It will enable the compiler to
make further optimizations --

00:28:16.456 --> 00:28:18.466 A:middle
for instance, more
aggressive specialization --

00:28:18.736 --> 00:28:20.736 A:middle
and by allowing the compiler

00:28:20.736 --> 00:28:22.996 A:middle
to better understand your
API's class hierarchy,

00:28:23.316 --> 00:28:25.686 A:middle
without any work on your
part, you can benefit

00:28:25.686 --> 00:28:30.326 A:middle
from increased elimination
of dynamic dispatch.

00:28:30.426 --> 00:28:32.716 A:middle
Now I'd like to turn this
presentation over to Joe,

00:28:32.716 --> 00:28:35.206 A:middle
who will show you how you
can use these techniques

00:28:35.276 --> 00:28:37.396 A:middle
and instruments to
improve the performance

00:28:37.606 --> 00:28:39.386 A:middle
of your application today.

00:28:40.516 --> 00:28:46.366 A:middle
[Applause]

00:28:46.866 --> 00:28:48.356 A:middle
&gt;&gt; JOE GRZYWACZ:
Thank you, Michael.

00:28:48.766 --> 00:28:49.796 A:middle
My name is Joe Grzywacz.

00:28:49.796 --> 00:28:51.396 A:middle
I am an engineer on
the Instruments Team,

00:28:51.526 --> 00:28:52.256 A:middle
and today I want to take you

00:28:52.256 --> 00:28:54.806 A:middle
through a demo application
that's running a little slowly

00:28:54.806 --> 00:29:03.686 A:middle
right now, so let's get started.



00:28:54.806 --> 00:29:03.686 A:middle
right now, so let's get started.

00:29:03.766 --> 00:29:04.566 A:middle
All right.

00:29:08.596 --> 00:29:11.576 A:middle
So here we have my Swift
application that's running

00:29:11.576 --> 00:29:14.966 A:middle
slowly, so what I want to do
is go ahead and click and hold

00:29:14.966 --> 00:29:17.126 A:middle
on the Run button
and choose Profile.

00:29:17.126 --> 00:29:19.436 A:middle
That's going to build my
application in release mode

00:29:19.496 --> 00:29:21.316 A:middle
and then launch instruments
as template choosers

00:29:21.316 --> 00:29:23.066 A:middle
so we can decide how we
want to profile this.

00:29:23.376 --> 00:29:25.726 A:middle
Since it's running slowly,
a good place to start is

00:29:25.726 --> 00:29:27.076 A:middle
with the time profiler template.

00:29:28.256 --> 00:29:30.316 A:middle
From Instruments,
just press Record,

00:29:30.816 --> 00:29:33.736 A:middle
your application launches, and
Instruments is recording data

00:29:33.736 --> 00:29:35.086 A:middle
in the background
about what it's doing.

00:29:35.666 --> 00:29:36.546 A:middle
So here we can see
we are running

00:29:36.546 --> 00:29:38.596 A:middle
at 60 frames per second
before I've started anything,

00:29:38.926 --> 00:29:41.256 A:middle
which is my target performance.

00:29:41.636 --> 00:29:43.456 A:middle
But as soon as I add these
particles to the screen,

00:29:43.546 --> 00:29:45.136 A:middle
they are moving around and
avoiding each other just

00:29:45.136 --> 00:29:47.246 A:middle
like I wanted, but we
are running at only

00:29:47.246 --> 00:29:48.606 A:middle
about 38 frames per second.

00:29:48.646 --> 00:29:50.306 A:middle
We lost about a third
of our performance.

00:29:50.306 --> 00:29:52.226 A:middle
Now that we have
reproduced the problem,

00:29:52.666 --> 00:29:55.296 A:middle
we can quit our application
and come back to Instruments.

00:29:56.106 --> 00:29:57.136 A:middle
Let me make this a
little bit larger

00:29:57.136 --> 00:29:58.086 A:middle
so we can see what's going on.

00:29:58.846 --> 00:30:01.606 A:middle
You can just drag
this, drag that around.



00:29:58.846 --> 00:30:01.606 A:middle
You can just drag
this, drag that around.

00:30:01.816 --> 00:30:03.416 A:middle
View Snap Track to Fit is handy

00:30:03.416 --> 00:30:05.146 A:middle
to make your data fill
your horizontal time.

00:30:05.836 --> 00:30:06.796 A:middle
Now what are we looking at?

00:30:06.866 --> 00:30:09.356 A:middle
Here in the track view,
this is our CPU usage

00:30:09.356 --> 00:30:10.086 A:middle
of our application.

00:30:10.196 --> 00:30:13.366 A:middle
We can see on the left before I
did anything, CPU usage was low;

00:30:13.756 --> 00:30:16.256 A:middle
after I added those particles,
CPU usage became higher.

00:30:16.656 --> 00:30:18.726 A:middle
You can see what those values
are by moving your mouse

00:30:18.726 --> 00:30:20.816 A:middle
and hovering it inside
this ruler view.

00:30:21.226 --> 00:30:24.276 A:middle
You can see prior we were around
10% or so, not doing much.

00:30:24.656 --> 00:30:26.926 A:middle
Later on we moved around 100%.

00:30:26.926 --> 00:30:28.336 A:middle
So we saturated our CPU.

00:30:28.646 --> 00:30:30.606 A:middle
In order to increase
our performance,

00:30:30.836 --> 00:30:32.516 A:middle
we need to decrease how
much work we're doing.

00:30:33.166 --> 00:30:34.386 A:middle
So what work were we doing?

00:30:34.716 --> 00:30:37.236 A:middle
That's where this detail
pane down below comes in.

00:30:38.496 --> 00:30:39.846 A:middle
So here's all of our threads.

00:30:40.226 --> 00:30:41.606 A:middle
Go ahead and open
this up a little bit.

00:30:41.606 --> 00:30:43.576 A:middle
You are probably familiar
with this call stack

00:30:43.576 --> 00:30:46.056 A:middle
from seeing it inside of
Xcode in the debugger.

00:30:46.316 --> 00:30:49.346 A:middle
Start, calls main, calls NS
application main, et cetera.

00:30:49.346 --> 00:30:51.046 A:middle
But what Instruments
is also going

00:30:51.046 --> 00:30:53.636 A:middle
to tell you is how much time
you were spending inside

00:30:53.636 --> 00:30:55.446 A:middle
of that function,
including its children,

00:30:55.846 --> 00:30:57.466 A:middle
right here in this first
column Running Time.

00:30:57.546 --> 00:31:01.436 A:middle
We can see 11,220 milliseconds,
or 99% of our time,



00:30:57.546 --> 00:31:01.436 A:middle
We can see 11,220 milliseconds,
or 99% of our time,

00:31:01.796 --> 00:31:04.136 A:middle
was spent in NSApplication
Main or the things it called.

00:31:04.666 --> 00:31:05.776 A:middle
The second column, Self,

00:31:05.776 --> 00:31:07.516 A:middle
is how much time the
instrument sampled inside

00:31:07.516 --> 00:31:09.996 A:middle
that function itself, so
it excludes its children.

00:31:10.876 --> 00:31:11.996 A:middle
So what I want to
do is see where does

00:31:11.996 --> 00:31:13.766 A:middle
that self number get
larger, and that means

00:31:13.766 --> 00:31:15.586 A:middle
that function is actually
performing a lot of work.

00:31:16.096 --> 00:31:18.546 A:middle
You can continue opening these
up one by one, hunting around,

00:31:18.606 --> 00:31:19.686 A:middle
but that can take
a little while.

00:31:20.436 --> 00:31:22.616 A:middle
Instead we recommend you come
over here to the right side,

00:31:22.806 --> 00:31:24.046 A:middle
this extended detail view,

00:31:24.046 --> 00:31:26.886 A:middle
and Instruments will show you
the single heaviest stack trace

00:31:26.886 --> 00:31:27.596 A:middle
in your application.

00:31:27.596 --> 00:31:29.726 A:middle
That's where it sampled
the most number of times.

00:31:30.036 --> 00:31:31.396 A:middle
You can see again here
is our main thread,

00:31:31.396 --> 00:31:34.006 A:middle
it took 11,229 milliseconds.

00:31:34.236 --> 00:31:35.856 A:middle
It began in Start.

00:31:35.936 --> 00:31:37.986 A:middle
Symbols in gray are
system frameworks.

00:31:38.276 --> 00:31:40.616 A:middle
Symbols in black here,
like Main, are your code.

00:31:40.616 --> 00:31:42.966 A:middle
And what I'd like to do is just
look down this list and see

00:31:42.966 --> 00:31:43.926 A:middle
if it's kind of a big jump.

00:31:43.926 --> 00:31:46.626 A:middle
That means something interesting
happened around this time.

00:31:46.626 --> 00:31:47.496 A:middle
If I scan down this list,

00:31:47.496 --> 00:31:49.046 A:middle
the number is slowly
getting smaller,

00:31:49.046 --> 00:31:52.026 A:middle
but there's no big jumps going
on, until I get down here

00:31:52.106 --> 00:31:54.696 A:middle
where I see a jump from
about 9,000 to about 4,000.

00:31:54.696 --> 00:31:55.756 A:middle
So something happened there.

00:31:55.756 --> 00:31:57.536 A:middle
I am going to go ahead
and click on my code,

00:31:58.176 --> 00:32:00.246 A:middle
and Instruments has
automatically expanded the call



00:31:58.176 --> 00:32:00.246 A:middle
and Instruments has
automatically expanded the call

00:32:00.246 --> 00:32:02.336 A:middle
tree on the left side so you can
see what you just clicked on.

00:32:03.566 --> 00:32:04.796 A:middle
Let me frame this up.

00:32:06.226 --> 00:32:07.196 A:middle
And what's going on here?

00:32:07.816 --> 00:32:09.476 A:middle
Well, if I back up just a
little bit for a moment,

00:32:09.476 --> 00:32:12.616 A:middle
here is my NSFiretimer call,
what's driving my simulation,

00:32:12.616 --> 00:32:14.156 A:middle
trying to get at 60
frames per second.

00:32:14.736 --> 00:32:18.766 A:middle
Down here is my particle
Sim.app delegate.update routine,

00:32:19.106 --> 00:32:20.846 A:middle
that's my Swift routine
driving my simulation.

00:32:21.446 --> 00:32:25.006 A:middle
But in between is this weird
@objc thing sitting here.

00:32:25.586 --> 00:32:27.706 A:middle
I want to point out
that's just a thunk.

00:32:27.826 --> 00:32:30.856 A:middle
Basically, it's a compiler
inserted function that gets us

00:32:30.856 --> 00:32:34.026 A:middle
from the Objective-C
world here in NSFiretimer

00:32:34.466 --> 00:32:36.956 A:middle
down to the Swift world
down here inside of my code.

00:32:37.316 --> 00:32:37.916 A:middle
That's all it is.

00:32:37.916 --> 00:32:38.806 A:middle
Otherwise, we can ignore it.

00:32:39.566 --> 00:32:42.456 A:middle
Now, we can see my update
routine is taking 89%

00:32:42.456 --> 00:32:43.916 A:middle
of the time, so continuing

00:32:43.916 --> 00:32:45.656 A:middle
to optimize this
function is a good idea.

00:32:45.656 --> 00:32:48.056 A:middle
So everything else above it is
not really interesting to me.

00:32:48.146 --> 00:32:50.236 A:middle
I am going to go ahead
and hide it by focusing

00:32:50.236 --> 00:32:51.896 A:middle
in on just this update routine

00:32:51.896 --> 00:32:53.586 A:middle
by clicking this arrow
here on the right.

00:32:54.536 --> 00:32:56.106 A:middle
Everything else around
this has been hidden.

00:32:56.556 --> 00:32:59.406 A:middle
Running time has been
renormalized to 100%,

00:32:59.406 --> 00:33:02.356 A:middle
just to help you do a
little less mental math.



00:32:59.406 --> 00:33:02.356 A:middle
just to help you do a
little less mental math.

00:33:02.356 --> 00:33:04.126 A:middle
If we look in on what's
going on in this function,

00:33:04.166 --> 00:33:06.636 A:middle
Update Phase Avoid calls
Find Nearest Neighbor,

00:33:07.076 --> 00:33:09.416 A:middle
that calls down into something
really interesting here.

00:33:09.856 --> 00:33:12.956 A:middle
We see Swift release is
taking 40% of our time,

00:33:13.026 --> 00:33:15.996 A:middle
and Swift retain is taking
another 35% of our time.

00:33:16.106 --> 00:33:19.546 A:middle
So between just these two
functions, we are doing

00:33:19.546 --> 00:33:20.396 A:middle
about three-quarters

00:33:20.396 --> 00:33:22.876 A:middle
of our update routine is just
managing reference counts.

00:33:23.616 --> 00:33:24.526 A:middle
Far from ideal.

00:33:24.626 --> 00:33:26.046 A:middle
So what's going on here?

00:33:26.566 --> 00:33:28.676 A:middle
Well, if I double-click on my
Find Nearest Neighbor routine

00:33:29.686 --> 00:33:31.366 A:middle
that calls those
retains releases,

00:33:31.366 --> 00:33:32.776 A:middle
Instruments will show
you the source code.

00:33:33.256 --> 00:33:35.736 A:middle
However, Swift is an automatic
reference counted language,

00:33:35.736 --> 00:33:37.376 A:middle
so you are not going
to see the releases

00:33:37.376 --> 00:33:38.556 A:middle
and retains here directly.

00:33:39.206 --> 00:33:41.946 A:middle
But you can, if you go over
to the disassembly view,

00:33:42.636 --> 00:33:43.656 A:middle
click on that button there,

00:33:44.206 --> 00:33:46.336 A:middle
Instruments will show you what
the compiler actually generated.

00:33:46.856 --> 00:33:47.946 A:middle
And you can hunt around in here

00:33:47.946 --> 00:33:49.616 A:middle
and see there's a
bunch of calls here.

00:33:49.616 --> 00:33:52.426 A:middle
There's 23% of the
time on this release.

00:33:52.746 --> 00:33:54.646 A:middle
There's some more
retains and releases here.

00:33:54.646 --> 00:33:55.946 A:middle
There is another
release down here.

00:33:55.946 --> 00:33:57.076 A:middle
They are all over the place.

00:33:57.156 --> 00:33:58.686 A:middle
So what can we do about that?

00:33:59.846 --> 00:34:04.176 A:middle
Let's return to our code here
and go to my particle file.



00:33:59.846 --> 00:34:04.176 A:middle
Let's return to our code here
and go to my particle file.

00:34:04.316 --> 00:34:05.596 A:middle
Here is my class Particle,

00:34:05.636 --> 00:34:07.056 A:middle
so it's an internal
class by default.

00:34:07.056 --> 00:34:09.306 A:middle
And it adheres to some
collidable protocol.

00:34:09.686 --> 00:34:10.016 A:middle
All right.

00:34:11.106 --> 00:34:13.775 A:middle
Down below is -- this is the
Find Nearest Neighbor routine

00:34:13.775 --> 00:34:15.286 A:middle
that was taking all
of that time before.

00:34:15.956 --> 00:34:19.255 A:middle
Now, I know that when the update
timer fires, that code is going

00:34:19.255 --> 00:34:21.246 A:middle
to call Find Nearest Neighbor
on every single particle

00:34:21.246 --> 00:34:24.786 A:middle
on the screen, and then there's
this interfor loop that's going

00:34:24.786 --> 00:34:26.926 A:middle
to iterate over every single
particle on the screen.

00:34:27.076 --> 00:34:30.396 A:middle
We have an N-squared
algorithm here or effectively,

00:34:30.396 --> 00:34:32.146 A:middle
the stuff that happens
inside this for loop is going

00:34:32.146 --> 00:34:33.806 A:middle
to happen a really
large number of times.

00:34:34.436 --> 00:34:37.216 A:middle
Whatever we do to optimize this
thing should have big payoff.

00:34:37.815 --> 00:34:38.636 A:middle
So what is going on?

00:34:39.016 --> 00:34:40.466 A:middle
We have our for loop itself

00:34:40.466 --> 00:34:42.275 A:middle
where we access one
of those particles.

00:34:42.275 --> 00:34:43.735 A:middle
So there's some retain
release overhead.

00:34:44.416 --> 00:34:46.755 A:middle
There are property
getters being called here,

00:34:46.755 --> 00:34:47.896 A:middle
this dot ID property.

00:34:48.246 --> 00:34:49.426 A:middle
And as Michael was
talking about,

00:34:49.426 --> 00:34:50.755 A:middle
since this is an internal class,

00:34:50.786 --> 00:34:52.246 A:middle
there might be some other
Swift files somewhere

00:34:52.246 --> 00:34:54.866 A:middle
that overrides these property
getters, so we are going

00:34:54.866 --> 00:34:56.565 A:middle
to be performing
a dynamic dispatch

00:34:56.886 --> 00:34:57.916 A:middle
to these property getters,

00:34:57.916 --> 00:34:59.706 A:middle
which has retain/release
overhead as well.



00:35:00.976 --> 00:35:03.096 A:middle
Down here there is this
distance squared function call.

00:35:03.616 --> 00:35:06.596 A:middle
Despite the fact that it lives
literally a dozen source code

00:35:06.596 --> 00:35:08.426 A:middle
lines away, once
again, we are going

00:35:08.426 --> 00:35:11.306 A:middle
to be doing a dynamic dispatch
to this routine with all

00:35:11.306 --> 00:35:13.236 A:middle
of that overhead as well as
the retain release overhead.

00:35:13.676 --> 00:35:16.076 A:middle
So what can we do
about this code?

00:35:16.336 --> 00:35:18.006 A:middle
Well, this code is complete.

00:35:18.316 --> 00:35:20.096 A:middle
I wrote this application,
I am finished,

00:35:20.096 --> 00:35:21.576 A:middle
my particle class is complete,

00:35:21.716 --> 00:35:23.366 A:middle
and I have no need
to subclass it.

00:35:23.576 --> 00:35:25.586 A:middle
So what I should do is
communicate my intention

00:35:25.586 --> 00:35:28.186 A:middle
to the compiler by marking
this class as final.

00:35:28.226 --> 00:35:32.746 A:middle
So with that one little
change, let's go ahead

00:35:32.746 --> 00:35:35.066 A:middle
and profile application
again and see what happened.

00:35:36.516 --> 00:35:39.386 A:middle
This time, the compiler was
able to compile that file,

00:35:39.386 --> 00:35:41.856 A:middle
knowing that there are
no other subclasses

00:35:41.856 --> 00:35:44.456 A:middle
of that particle file --
particle class, excuse me --

00:35:44.876 --> 00:35:46.356 A:middle
and that means it's able

00:35:46.356 --> 00:35:48.606 A:middle
to perform additional
optimizations.

00:35:48.856 --> 00:35:50.536 A:middle
It can call those
functions directly,

00:35:50.536 --> 00:35:53.396 A:middle
maybe even inline them, or any
other number of optimizations

00:35:53.626 --> 00:35:55.796 A:middle
that can reduce the
overhead that we had before.

00:35:56.586 --> 00:36:00.276 A:middle
So if we record, this time
when I add the particles,



00:35:56.586 --> 00:36:00.276 A:middle
So if we record, this time
when I add the particles,

00:36:00.276 --> 00:36:01.926 A:middle
we can see they are
moving around and running

00:36:01.926 --> 00:36:03.586 A:middle
around at 60 frames per
second at this time,

00:36:03.586 --> 00:36:05.566 A:middle
so we got back 20 frames
per second with just

00:36:05.566 --> 00:36:06.666 A:middle
that one small change.

00:36:07.286 --> 00:36:08.246 A:middle
That's looking good.

00:36:08.456 --> 00:36:09.926 A:middle
However, as you may guess,

00:36:09.926 --> 00:36:12.136 A:middle
I have a second phase
here called collision

00:36:12.136 --> 00:36:13.586 A:middle
where we swap the algorithm

00:36:13.586 --> 00:36:14.936 A:middle
and now they are
bouncing off one another,

00:36:15.246 --> 00:36:17.776 A:middle
and again our frame rate
dropped by about 25 percent

00:36:17.776 --> 00:36:19.346 A:middle
down to 45 frames per second.

00:36:19.966 --> 00:36:23.096 A:middle
We reproduced the problem again,
let's return to Instruments

00:36:23.256 --> 00:36:24.746 A:middle
and see what's happening.

00:36:24.746 --> 00:36:28.496 A:middle
We will do what we do before,
make this a little bit larger,

00:36:29.036 --> 00:36:32.376 A:middle
Snap Track to Fit, and
now what do we see?

00:36:32.376 --> 00:36:35.466 A:middle
Over here on the left, this
was our avoidance phase.

00:36:35.566 --> 00:36:39.456 A:middle
Things are running much
better, around 30%, 40% or so,

00:36:39.456 --> 00:36:41.586 A:middle
so that's why we are hitting
our 60 frames per second.

00:36:42.376 --> 00:36:45.186 A:middle
But over here on the right,
this is our collision phase.

00:36:45.216 --> 00:36:48.486 A:middle
And now this is capping
out at 100% of our CPU,

00:36:48.746 --> 00:36:50.286 A:middle
and that's why our frame
rate is suffering again.

00:36:50.966 --> 00:36:54.996 A:middle
We did what we did a moment ago
right now, this call tree data

00:36:54.996 --> 00:36:57.656 A:middle
down here in the detail
pane is going to have data

00:36:57.656 --> 00:36:59.666 A:middle
from this avoidance phase,
which is running fine,

00:36:59.966 --> 00:37:02.516 A:middle
as well as this collision phase,
which is what I really want



00:36:59.966 --> 00:37:02.516 A:middle
as well as this collision phase,
which is what I really want

00:37:02.516 --> 00:37:04.216 A:middle
to actually be focusing on.

00:37:04.216 --> 00:37:06.956 A:middle
So that avoidance
sample over here is going

00:37:06.956 --> 00:37:08.156 A:middle
to water down our results.

00:37:08.516 --> 00:37:10.996 A:middle
Instead, I would like to set a
time filter so I am only looking

00:37:10.996 --> 00:37:11.926 A:middle
at my collision phase.

00:37:12.286 --> 00:37:13.376 A:middle
That's really simple to do.

00:37:13.376 --> 00:37:15.496 A:middle
Just click and drag
in the timeline view,

00:37:16.076 --> 00:37:17.596 A:middle
and now our detail
pane has been updated

00:37:17.596 --> 00:37:19.916 A:middle
to only consider the samples
from our collision phase.

00:37:20.856 --> 00:37:22.486 A:middle
Now we can do what
we did before,

00:37:22.486 --> 00:37:24.766 A:middle
head over to our
extended detail view.

00:37:25.696 --> 00:37:28.766 A:middle
Look down this list,
see where we see a jump,

00:37:28.766 --> 00:37:30.406 A:middle
and something interesting
happens here,

00:37:30.406 --> 00:37:32.646 A:middle
we went from about
8,000 milliseconds

00:37:32.646 --> 00:37:33.916 A:middle
to 2,000 milliseconds.

00:37:33.916 --> 00:37:36.616 A:middle
So I am going to click on my
collision detection class here.

00:37:37.696 --> 00:37:40.216 A:middle
Instruments once again
automatically expands this call

00:37:40.216 --> 00:37:40.896 A:middle
tree for us.

00:37:41.636 --> 00:37:43.386 A:middle
And if we just kind of look
at what's going on here,

00:37:43.536 --> 00:37:47.036 A:middle
88% of my time is spend inside
of this runtime step routine.

00:37:47.036 --> 00:37:48.356 A:middle
This is a good place to dig in.

00:37:48.936 --> 00:37:50.516 A:middle
I'll do what I did
before and click

00:37:50.516 --> 00:37:52.006 A:middle
on this Focus arrow
here on the right.

00:37:52.056 --> 00:37:54.576 A:middle
Now we are looking at just
our runtime step routine,

00:37:55.306 --> 00:37:56.416 A:middle
and let's see what it's doing.

00:37:57.286 --> 00:37:57.546 A:middle
All right.

00:37:57.546 --> 00:37:59.756 A:middle
Well, 25% of its time
is being spent inside

00:37:59.756 --> 00:38:02.286 A:middle
of Swift.array.underscore
getelement.



00:37:59.756 --> 00:38:02.286 A:middle
of Swift.array.underscore
getelement.

00:38:02.956 --> 00:38:05.726 A:middle
When you see this A
inside of angle brackets,

00:38:05.816 --> 00:38:07.706 A:middle
that means you are calling
into the generic form

00:38:07.706 --> 00:38:10.166 A:middle
of that function and all
the overhead that entails.

00:38:10.786 --> 00:38:12.976 A:middle
You will see this
again here inside

00:38:12.976 --> 00:38:15.416 A:middle
of Swift array is
valid subscript,

00:38:15.716 --> 00:38:17.646 A:middle
there's that A inside
of angle brackets.

00:38:18.036 --> 00:38:19.356 A:middle
It also happens when you have

00:38:19.356 --> 00:38:20.896 A:middle
that A inside of
square brackets.

00:38:20.896 --> 00:38:23.426 A:middle
So we are calling a generic
property getter here.

00:38:23.676 --> 00:38:26.276 A:middle
So just between these
three generic functions,

00:38:26.276 --> 00:38:31.006 A:middle
we are looking at about 50% of
our time is being spent inside

00:38:31.006 --> 00:38:32.126 A:middle
of these generic functions.

00:38:32.456 --> 00:38:34.726 A:middle
So what can we do about
getting rid of that overhead?

00:38:34.726 --> 00:38:37.226 A:middle
All right, back over to Xcode.

00:38:38.456 --> 00:38:40.326 A:middle
Here is my collision
detection file.

00:38:40.866 --> 00:38:43.006 A:middle
Here we can see that
collidable protocol

00:38:43.106 --> 00:38:44.586 A:middle
that my particle
was adhering to.

00:38:45.016 --> 00:38:47.356 A:middle
Here is that generic
class, class detection,

00:38:47.666 --> 00:38:50.226 A:middle
type T that adheres to
a collidable protocol.

00:38:50.776 --> 00:38:53.526 A:middle
What does it do, well it has
this collidables array here,

00:38:53.526 --> 00:38:54.816 A:middle
that's of generic type T.

00:38:55.446 --> 00:38:58.296 A:middle
And here down below is
our runtime step routine,

00:38:58.436 --> 00:39:00.566 A:middle
and that's where we were
spending all of our time.



00:38:58.436 --> 00:39:00.566 A:middle
and that's where we were
spending all of our time.

00:39:00.976 --> 00:39:02.286 A:middle
So what does this function do?

00:39:02.646 --> 00:39:05.796 A:middle
Well, it iterates over all
our collidables, accesses one

00:39:05.796 --> 00:39:08.306 A:middle
of the collidables from
that array, calls a bunch

00:39:08.306 --> 00:39:09.726 A:middle
of property getters here.

00:39:10.026 --> 00:39:10.726 A:middle
Here's some more.

00:39:11.056 --> 00:39:13.366 A:middle
There is an interfor
loop, where we do kind

00:39:13.366 --> 00:39:14.536 A:middle
of the same thing again, we pull

00:39:14.536 --> 00:39:16.426 A:middle
out another second
collidable from that array.

00:39:16.726 --> 00:39:18.406 A:middle
Then all sorts of property
getters down below.

00:39:18.566 --> 00:39:21.386 A:middle
We're doing a lot of generic
operations here, and we'd really

00:39:21.386 --> 00:39:22.856 A:middle
like to get rid of that.

00:39:22.856 --> 00:39:23.626 A:middle
How do we do that?

00:39:24.176 --> 00:39:28.406 A:middle
Well, this time you can see my
collision detection class is

00:39:28.406 --> 00:39:29.726 A:middle
here inside of this Swift file.

00:39:30.096 --> 00:39:33.996 A:middle
However, the users of this,

00:39:34.126 --> 00:39:36.196 A:middle
where I am using this class
is inside this app delegate

00:39:36.196 --> 00:39:38.746 A:middle
routine, this particle Swift
file, so it's in other parts

00:39:38.746 --> 00:39:40.676 A:middle
of this module, so we
are going to have to turn

00:39:40.676 --> 00:39:41.966 A:middle
to Whole Module Optimization.

00:39:42.716 --> 00:39:45.166 A:middle
Doing that's really easy,
just click on your project.

00:39:46.356 --> 00:39:48.206 A:middle
Go over here to build settings.

00:39:48.626 --> 00:39:50.436 A:middle
Make sure you are looking at
all of your build settings.

00:39:50.916 --> 00:39:52.906 A:middle
Then just do a search
for optimization.

00:39:54.046 --> 00:39:57.006 A:middle
And here is that setting that
Nadav showed you earlier.

00:39:57.106 --> 00:39:58.786 A:middle
You just want to switch
your release build

00:39:58.816 --> 00:40:00.376 A:middle
over to Whole Module
Optimization.



00:39:58.816 --> 00:40:00.376 A:middle
over to Whole Module
Optimization.

00:40:01.046 --> 00:40:03.406 A:middle
And now when we profile, the
compiler is going to look

00:40:03.406 --> 00:40:07.236 A:middle
at all those files together and
build a more optimized binary,

00:40:07.446 --> 00:40:08.606 A:middle
but let's check and
see what happened.

00:40:09.286 --> 00:40:11.306 A:middle
So we will launch time profiler
for the third time here,

00:40:12.006 --> 00:40:15.746 A:middle
start our recording, and
60 frames per second,

00:40:16.166 --> 00:40:18.566 A:middle
we add our particles, this
avoidance phase still running

00:40:18.566 --> 00:40:19.736 A:middle
at 60 frames per second.

00:40:19.876 --> 00:40:21.426 A:middle
Good, I expected
that not to change.

00:40:21.466 --> 00:40:22.426 A:middle
Always good to verify.

00:40:23.046 --> 00:40:24.906 A:middle
Then we move over to
our collision phase.

00:40:24.976 --> 00:40:27.666 A:middle
Now that is running at 60
frames per second as well.

00:40:28.076 --> 00:40:30.376 A:middle
All it took was a couple
minutes of analysis

00:40:30.376 --> 00:40:31.626 A:middle
and a few small tweaks,

00:40:31.726 --> 00:40:33.496 A:middle
and we made our application
a lot faster.

00:40:34.516 --> 00:40:41.696 A:middle
[Applause]

00:40:42.196 --> 00:40:42.846 A:middle
All right.

00:40:42.846 --> 00:40:44.166 A:middle
So to summarize what
we saw here today,

00:40:44.566 --> 00:40:47.006 A:middle
we know that Swift is a
flexible programming language

00:40:47.296 --> 00:40:48.686 A:middle
that uses -- that's safe

00:40:48.686 --> 00:40:50.236 A:middle
and uses automatic
reference counting

00:40:50.306 --> 00:40:51.656 A:middle
to perform its memory
management.

00:40:51.936 --> 00:40:53.916 A:middle
Now, those powerful features
are what make it a delight

00:40:53.916 --> 00:40:56.416 A:middle
to program in, but they
can come with a cost.

00:40:56.596 --> 00:40:59.446 A:middle
What we want you to do is focus
on your APIs and your code

00:40:59.446 --> 00:41:01.816 A:middle
that when you are writing them,
you keep performance in mind.



00:40:59.446 --> 00:41:01.816 A:middle
that when you are writing them,
you keep performance in mind.

00:41:01.816 --> 00:41:04.316 A:middle
And how do you know what
costs you are paying for?

00:41:04.766 --> 00:41:06.596 A:middle
Profile your application
inside of Instruments,

00:41:06.596 --> 00:41:07.976 A:middle
and do it throughout
the lifetime

00:41:07.976 --> 00:41:10.756 A:middle
of your application development
so that when you find a problem,

00:41:10.786 --> 00:41:13.506 A:middle
you find it sooner and you
can react to that more easily,

00:41:13.506 --> 00:41:16.686 A:middle
especially if it involves
changing some of your APIs.

00:41:17.456 --> 00:41:19.506 A:middle
There's documentation
online, of course.

00:41:19.506 --> 00:41:22.146 A:middle
The Developer Forums where you
can go, and you will be able

00:41:22.146 --> 00:41:23.876 A:middle
to ask questions about
Swift and get them answered,

00:41:23.876 --> 00:41:25.086 A:middle
as well as Instruments.

00:41:26.336 --> 00:41:28.356 A:middle
And speaking of Instruments,
there's a Profiling

00:41:28.356 --> 00:41:30.586 A:middle
in Depth talk today
in Mission at 3:30.

00:41:30.586 --> 00:41:33.056 A:middle
There is an entire session
devoted to Time Profiler

00:41:33.056 --> 00:41:34.446 A:middle
and getting into even more depth

00:41:34.506 --> 00:41:35.956 A:middle
than we're able to
get into today.

00:41:36.386 --> 00:41:37.596 A:middle
And as Michael talked
about earlier,

00:41:37.596 --> 00:41:40.106 A:middle
there is a Building Better
Apps with Value Types in Swift

00:41:40.106 --> 00:41:42.086 A:middle
that will also build
upon what you saw today.

00:41:42.086 --> 00:41:42.906 A:middle
So thank you very much.

00:41:43.516 --> 00:41:47.500 A:middle
[Applause]

